# Яндекс Практикум
- Список для чтения
    - [ ]  Демистификация контейнеров **— [часть I: пространство ядра](https://medium.com/@saschagrunert/demystifying-containers-part-i-kernel-space-2c53d6979504)**
    - [ ]  [Документация Docker](https://docs.docker.com/get-started/)
    - [ ]  [Kubernetes](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)




## 1. Облачные технологии, сервисы и что внутри

### **Что такое облачные технологии**

Облачные платформы позволяют арендовать IT-ресурсы: серверы, базы данных, IP-адреса, сетевую инфраструктуру или даже нейросети.

**Преимущества:**

- Разделение ответственности
    
    > вы как пользователь не беспокоитесь об издержках владения техникой и её обслуживания. Сервер вышел из строя, жёсткий диск перестал работать, сисадмин на больничном? Всё это не ваша головная боль. Вы можете сосредоточиться на своём продукте или бизнесе.
    > 
- Масштабируемость
    
    > не требуется докупать, устанавливать, настраивать физическое оборудование и иметь для всего этого специалиста, можно в пару кликов увеличить вычислительные мощности
    > 
- Экономия
    
    > Во-первых, при аналогичном для бизнеса результате вы экономите время, деньги и усилия, которые пришлось бы потратить на техническую поддержку оборудования.
    > 
    > 
    > Во-вторых, вы платите только за то, чем пользуетесь. Например, если вы остановили свою виртуальную машину, то оплачивать её вычислительные ресурсы не нужно.
    > 
    > Но нужно платить за бронирование
    > 

Облачная платформа предоставляет вам IT-инфраструктуру и сервисы в аренду. Вы пользуетесь ими, когда они нужны, и освобождаете, когда в них больше нет необходимости. Такой принцип аренды называется **as a Service** — как сервис.

Три уровня

- **Infrastructure** as a Service (**IaaS**)
    
    базовый уровень, в него входит аренда виртуальных серверов, сетей и всего что с ними связано.
    
    > С помощью IaaS вы можете отправить в облако сайт, бэкэнд мобильного приложения, систему Continuous Integration для разработчиков или 1C для бухгалтерии. Кроме того, вы можете загружать и использовать собственные образы.
    > 
- **Platform** as a Service (**PaaS**)
    
    позволяет разворачивать с облаке современные веб-приложения, не думая об инфраструктурных элементах: ВМ и сетях. Это уровень поверх Infrastructure as a Service
    
    > Пример PaaS — управляемые базы данных (БД). Вам необязательно устанавливать и администрировать БД на виртуальной машине: купите БД нужного размера с автоматическим резервным копированием и другими полезными возможностями и сразу же начните пользоваться ей
    > 
- **Software** as a Service (**SaaS**)
    
    оплата за готовый софт, который развернут в облаке с помощью инфраструктурных и платформенных сервисов
    
    > Пример SaaS — GitLab, система для совместного управления кодом в командах разработки. Вы получаете готовое решение и не думаете о том, как оно устроено.
    > 

### **Облачные сервисы**

Сервисы Yndex Cloud делятся на 9 групп:

- **Инфраструктура и сеть** — инфраструктурные сервисы для обработки данных, безопасного доступа к ним и обмена трафиком.
    
    > Сервисы этой группы позволяют:
    > 
    > - разворачивать виртуальные серверы и сеть между ними (Yandex Compute Cloud, Yandex Virtual Private Cloud, Yandex Cloud Interconnect);
    > - адаптировать конфигурацию виртуальных машин под изменяющиеся нагрузки, строить отказоустойчивые решения (Yandex Network Load Balancer и Yandex Application Load Balancer);
    > - хранить данные в объектном хранилище (Yandex Object Storage);
    > - повышать безопасность решений (Yandex DDoS Protection);
    > - создавать API-шлюзы (Yandex API Gateway).
- **Платформа данных** — управление базами данных и кластерами, масштабируемое хранение данных, сбор и визуализация метрик и данных.
    
    > Сервисы Платформы данных позволяют:
    > 
    > - разворачивать кластеры баз данных (Managed Service for PostgreSQL, ClickHouse, MongoDB, MySQL, Redis, SQL Server, Apache Kafka, Elasticsearch, Greenplum, YDB);
    > - визуализировать и анализировать данные (Yandex DataLens);
    > - управлять кластерами Apache Hadoop (Yandex Data Proc);
    > - переносить базы данных с помощью Yandex Data Transfer;
    > - создавать очереди для обмена сообщениями между компонентами распределённых приложений и микросервисов (Yandex Message Queue).
- **Контейнерная разработка** — управление кластерами Kubernetes и Docker-образами, а также для запуска контейнеризированных приложений без Kubernetes
- **Инструменты разработчика** — сервисы для оптимизации разработки и тестирования приложений.
- **Бессерверные вычисления** — сервисы для хранения данных и разработки приложений без создания виртуальных машин.
    
    > Сервисы группы Бессерверные вычисления позволяют:
    > 
    > - запускать код в бессерверной архитектуре приложений (Yandex Cloud Functions);
    > - работать с устройствами интернета вещей (Yandex IoT Core);
    > - обмениваться данными между приложениями через сервис очередей (Yandex Message Queue);
    > - работать с базой данных с тарификацией по количеству запросов (Yandex Managed Service for YDB);
    > - применять сервис для управления API-шлюзами (Yandex API Gateway).
- **Безопасность** — управление ключами шифрования и TLS-сертификатами, защита от DDoS-атак.
    
    > Сервисы этой группы позволяют:
    > 
    > - управлять ключами шифрования (Yandex Key Management Service);
    > - защищать ресурсы от DDoS-атак (Yandex DDoS Protection);
    > - создавать и хранить логины и пароли, ключи сертификатов серверов, ключи сервисного аккаунта в облаке и других конфиденциальных данных (Yandex Lockbox);
    > - управлять TLS-сертификатами (Yandex Certificate Manager).
- **Ресурсы и управление** — идентификация и контроль доступа к облачным ресурсам, управление ресурсами в каталогах и облаках.
    
    > С их помощью вы можете:
    > 
    > - идентифицировать и контролировать доступ к облачным ресурсам (Yandex Identity and Access Management);
    > - собирать и визуализировать метрики (Yandex Monitoring);
    > - управлять ресурсами в каталогах и облаках (Yandex Resource Manager);
    > - управлять сервисами организации (Yandex Cloud Organization);
    > - читать и записывать логи сервисов и пользовательских приложений (Yandex Cloud Logging).
- **Машинное обучение** — можно строить современные решения на базе технологий искусственного интеллекта: речевые технологии, анализ изображений и машинный перевод.
    
    > Yandex SpeechKit и Yandex Translate позволяют работать с голосом и текстом, Yandex Vision — анализировать изображенияYandex DataSphere — создавать модели машинного обучения.
    > 
- **Бизнес-инструменты** — визуализация и анализ данных, хранение базы знаний, трекер задач для организации работы команды.
    
    > объединяет инструменты для организации работы команды (Yandex Tracker), создания базы знаний (Yandex Wiki), настройки форм (Yandex Forms), визуализации и анализа данных (Yandex DataLens)сервис удаленных рабочих мест в облаке (Yandex Cloud Desktop).
    > 

### **Внутри облака**

Любые облака всегда начинаются с серверов, точнее с центров обработки данных (ЦОД), или дата-центров (ДЦ), где эти серверы строят.

> Инфраструктура Yandex Cloud состоит из трёх дата-центров. Они расположены в Подмосковье, Владимирской и Рязанской областях и связаны между собой собственными оптоволоконными сетями.
> 

**Зона доступности** - представляет собой независимый сегмент облачной инфраструктуры.

Три зоны доступности:

- `ru-central1-a`
- `ru-central1-b`
- `ru-central1-c`

Каждая зона отдельные ДЦ, независимые друг от друга. (сбой в одном не влияет на другие)

Серверное оборудование в узле собственной разработки:

- спроектировано с учетом допустимой рабочей температуры,
- напряжение на сервере 24 В,
- дисковое оборудование с возможностью горячей замены

### **Доступ к ресурсам**

Принципы использования платформы Yndex Cloud

- **ИЕРАРХИЯ РЕСУРСОВ**
    
    **ресурсы** - сущности, которые можно создать (ВМ, диски, виртуальные сети).
    
    Они объединены в группы - **каталоги**
    
    **Облако** - самая крупная логическая единица, она изолирована (ресурсы в облаке не могут взаимодействовать с ресурсами в другом облаке)
    
    > Облако (проект) 	<--	Каталоги (каталог1, каталог2 ...) 	<--	Ресурсы (ВМ, диски, сети)
    > 
    > 
    > Поскольку в одном облаке может быть много каталогов, в общем случае достаточно простой иерархии: один проект — один каталог внутри общего облака на компанию. Но если проектов и направлений много, иерархию можно построить иначе. Например, в вашей компании два больших направления: разработка игр и разработка систем интернета вещей. Для каждого направления создайте облако, для каждого проекта — каталог, а в каталог поместите ресурсы, которые касаются только этого проекта.
    > 
- **РОЛИ**
    
    Роли бывают двух типов:
    
    - **Примитивные**
        
        содержат разрешения, действующие для всех типов ресурсов Yandex Cloud.
        
        Это роли
        
        - `admin`,
            
            > Просматривать инф. о ресурсах
            > 
            > 
            > Управлять ресурсами
            > 
            > Настраивать доступ к ресурсам для других пользователей
            > 
        - `editor`
            
            > Просматривать инф. о ресурсах
            > 
            > 
            > Управлять ресурсами
            > 
        - `viewer`.
            
            > Просматривать инф. о ресурсах
            > 
    - **Сервисные**
        
        их много, тк они зависят от логики работы сервисов
        
        > Например, у Yandex Resource Manager есть две сервисные роли:
        > 
        > - `resource-manager.clouds.owner` — назначается только на облако, даёт полный доступ к облаку и ресурсам в нём;
        > - `resource-manager.clouds.member` — роль необходима для доступа к ресурсам в облаке другим пользователям без административных прав.
        
        В иерархии Облако → Каталог → Ресурс роли наследуются:
        
        - `resource-manager.clouds.owner`
            
            может выполнять любые действия с любым ресурсом в любом каталоге;
            
        - пользователь с ролями `resource-manager.clouds.member`
            
            на облако и `editor` на облако может управлять любыми ресурсами в любом каталоге;
            
        - `editor` каталога может управлять ресурсами только в своём каталоге.
        
        У каждого облака обязательно должен быть хотя бы один владелец (`owner`). У пользователя может быть роль `owner` в нескольких облаках.
        
    
    > Сервис Yandex Resource Manager определяет ресурсную модель Yandex Cloud и позволяет структурировать ресурсы с помощью каталогов. С его помощью вы также можете назначить пользователю роли, определяющие, какие действия этот пользователь может выполнять с доступными ресурсами.
    > 
- **ПОЛЬЗОВАТЕЛИ**
    
    Пользователем называется человек или программа, которые взаимодействуют с ресурсами. Они идентифицируются при помощи аккаунтов, их три:
    
    - Яндекс ID
        
        > единый аккаунт человека во всех сервисах Яндекса;
        > 
    - Федеративный аккаунт
        
        > акк. человека во внешних по отношению к Яндексу системах (апример, аккаунт в Microsoft Active Directory — популярной системе хранения информации о корпоративных пользователях;)
        > 
    - Сервисный аккаунт
        
        > акк. от имени которого программы могут управлять ресурсами
        > 

> Сервис Yandex Identity and Access Management (IAM) проверяет права пользователей на действия с ресурсами. Проверка прав называется авторизацией.
> 
> 
> Чтобы пользователь подтвердил личность, он должен пройти аутентификацию. Её способы зависят от типа аккаунта. Например, с Яндекс ID аутентификация происходит автоматически. Сервисные аккаунты аутентифицируются с помощью IAM-токена, API-ключей или статических ключей доступа.
> 

## 2. VM

### **Основная информация о виртуальных машинах**

ВМ - аналог физического сервера в инфраструктуре

> По сути, компьютер внутри компьютера, изолированный от операционной системы, в которой запущен.
> 

Внутри ВМ работает ОС с прикладным ПО, например с базой данных.  Для функционирования ей нужны:

- ядра процессора
- оперативная память
- диски

> Которые выделяются с сервера (из любой из 3 зон доступности)
> 

Чтобы установить, настроить или обновить приложение, можно подключиться в ВМ удаленно.

### **Создание виртуальной машины и подключение к ней.**

Создаю в интерфейсе Яндекса ВМ по алгоритму из [урока 3](https://practicum.yandex.ru/trainer/ycloud/lesson/467fb1f2-7eb4-421c-a33c-117e1cf86b66/)

**Создание SSH ключей**

1. Запустите терминал в Linux/macOS, либо утилиту `cmd.exe` или `powershell.exe` в Windows 10/11 и создайте пару ключей с помощью команды ssh-keygen:
`ssh-keygen -t ed25519`
    1. После выполнения команды указать имена файлов, куда сохранятся ключи
    *(имя файла пишется в том случае, если в скрытой папке .ssh ,которую можно найти по пути ~/.ssh/ ,уже есть созданная папка с этим именем, иначе они сохранятся хуй знает куда и ничего работать не будет)*
2. Введите пароль для закрытого ключа
*(я написал education1)*
    
    > По умолчанию используется имя id_ed25519, ключи создаются в папке ~/.ssh текущего пользователя.
    > 
    > 
    > Открытый ключ сохранится в файле `<имя_ключа>.pub`. Содержимое этого файла вставляется в поле **SSH-ключ** на странице создания ВМ.
    > 

Дальше по алгоритму из [урока 3](https://practicum.yandex.ru/trainer/ycloud/lesson/467fb1f2-7eb4-421c-a33c-117e1cf86b66/)  (с 10 шага)

**Удаленное подключение к ВМ**

Подключение к ВМ, для этого нужно:

- логин пользователя
- публичный IP-адрес ВМ

Для подключения к запущенной ВМ (статус RANNING) по протоколу SSH, используют утилиту `ssh`

1. В терминале необходимо выполнить команду:
    
    `ssh <имя_пользователя>@<публичный_IP-адрес_ВМ>`
    
2. Если несколько ключей:
`ssh -i <путь_к_ключу/имя_файла_ключа> <имя_пользователя>@<публичный_IP-адрес_ВМ>`
(при первом подключении может появиться предупреждение, нужно ввести yes)
3. Установить обновления:
    
    `sudo apt-get updatesudo apt-get upgrade`
    

### **Последовательный порт и серийная консоль**

Каждая запущенная ВМ создает порт ввода-вывода `COM1` , к которому можно подключиться.

> Если в ВМ произошел сбой, чтобы выяснить причину необходимо посмотреть журнал системных сообщений, если нет входа в ВМ по SSH или демон sshd (для Linux) не работает, нужно подключиться к последовательному порту COM1 ВМ и посмотреть инф. которая туда направляется.
> 

Путь конкретно в моем акк:

[Compute Cloud](https://console.cloud.yandex.ru/folders/b1gd4d7843kr3km8urvc/compute)/[Виртуальные машины](https://console.cloud.yandex.ru/folders/b1gd4d7843kr3km8urvc/compute/instances)/education1

и в меню слева выбрать последовательный порт.

Можно подключиться к порту `COM1` ВМ Linux или порту `COM2` ВМ Windows, чтобы вводить данные и администрировать ВМ. Эта функция называется **серийная консоль**

**Риски для безопасности:**

- вкл серийную консоль только по необходимости
- давать доступ только узкому кругу людей
- стойкий пароль для доступа к ВМ
- после работы с серийной консолью отключать доступ к ней в ВМ

### **Получить доступ к серийной консоли**

> Работа серийной консоли зависит от настроек ОС. Yandex Compute Cloud обеспечивает связь между пользователем и COM-портом, но не гарантирует стабильность работы консоли со стороны ОП системы ВМ
> 

Доступ к серийной консоли ВМ с ОС на базе Linux, способы:

- с другого ПК по протоколу SSH
- через консоль управления Yandex Cloud
- с помощью интерфейса командной строки Yandex Cloud CLI

Вход по протоколу SSH:

1. Подключиться по протоколу SSH (точно так-же как и подключались к ВМ ранее из урока 3)
2. Установить пароль к текущему пользователю утилитой `passwd` в привилегированном режиме (через `sudo`):
    
    `sudo passwd <имя_пользователя>`
    
    (дважды нужно ввести один пароль, *я ввел education1*)
    
3. Для доступа к консоли ВМ необходим ее идентификатор (ID), в списке ВМ он указан в правом столбце
4. Использовать в запросе идентификатор ВМ и имя (логин) созданного в ней пользователя:
    
    `ssh -t -p 9600 -o IdentitiesOnly=yes -i ~/.ssh/<имя закрытого ключа> <ID виртуальной машины>.<имя пользователя>@serialssh.cloud.yandex.net`
    
    > 'эта команда вводится с консоли личного пк, то есть на котором сгенерированы ssh ключи, то есть имя закрытого ключа - это имя файла где закрытый ssh ключ (он в скрытой паке ~/.shh/ , id виртуальной машины - это ее идентификатор (не публичный и не закрытый IP!!!!), а имя пользователя это имя самой ВМ)
    > 
5. Ввести ранее установленный пароль
6. Для отключения можно:
    - нажать `Enter`, затем ввести `~.`
    - Ctrl+D

### **Прерываемые машины и уровни производительности**

**Уровень производительности - vCPU** - определяет доступную ВМ долю вычислительного времени физических ядер:

- 100% - непрерывный доступ к вычислительной мощности физических ядер
- меньше 100% - имеют доступ к вычислительной мощности как минимум на протяжении указанного процента от единицы времени

> 100% для тех высоко производительных проектов, которые чувствительны к задержкам
> 

### **Сервис метаданных и cloud-init**

В Compute Cloud с каждой ВМ связаны метаданные.

Метаданные - это:

- идентификатор
- название и описание ВМ
- список подключенных к ней дисков и сетевых интерфейсов
- привязанные к ВМ сервисные аккаунты

так же можно определить дополнительные метаданные и указывать их, когда задается или изменяется ВМ.

Получить метаданные можно изнутри ВМ через сервис метаданных по адресу:  [http://169.254.169.254](http://169.254.169.254/)

Сервис возвращает метаданные в 2 форматах: Google Compute Engine или Amazon EC2.

> В ВМ на базе Linux для работы с метаданными, как правило, используется агент cloud-init, в машинах с Windows — Cloudbase-Init. Но вы можете отправить запрос в сервис метаданных и самостоятельно — с помощью любого HTTP-клиента.
> 

Передать метаданные можно при создании или изменении ВМ, обычно это делается через консольную утилиту Yandex Cloud CLI.

Указывайте метаданные в одном из 3 параметров:

- `-metadata` принимает список пар "ключ=значение", разделенных запятой, пример: -`metadata foo1=bar,foo2=baz`
- `-metadata-from-file` читает метаданные из файла, например: `metadata-from-file key=path/to/file` (удобно если нужно передать длинные метаданные)
- `-ssh-key` специальный тип метаданных для хранения публичного ключа (доступен тока на линуксе, его читает cloud-init)

> Чтобы получить метаданные ВМ от Yandex Cloud, вы можете использовать интерфейс командной строки Yandex Cloud (CLI) или API. Пошаговое руководство по использованию CLI для решения этой задачи приведено в документации.
> 

## 3. Диски, снимки и образы

### **Диски. Зависимость производительности от объема**

**Репликация** - это когда для каждого снимка и образа создается полная копия

Для ВМ могут использоваться сетевые диски:

- HDD
hard disk drive - накопитель на жестком магнитном диске. Низкая стоимость гигабайта, скорость ниже чем у SSD.
    
    > Они выбираются там, где скорость загрузки не критична (загрузочный диск)
    > 
- SSD
solid state disk - твердотельный накопитель. Позволяет выполнять больше операций считывания и записи в единицу времени.
    
    > Используются если нужно часто обращаться к файлам, быстро загружать тяжелые приложения (можно к примеру хранить БД)
    > 

**Загрузочные и дополнительные диски**

- Загрузочный - на нем находится ОС и приложения. Он не отключается от ВМ
- Дополнительный - можно хранить любые данные. Его можно отключить от ВМ

> Например есть веб-сервис с возможностью выгрузки данных, то само веб-приложение будет поверх операционной системы на загрузочном диске, а база данных и файлы выгрузки на дополнительных дисках
> 

### **Что такое снимок**

> На ВМ есть данные, с которыми работает приложение - чтобы их не потерять нужно создавать резервные копии , для этого и придуманы снимки.
> 

Снимок - слепок или поблочная копия дискового устройства на определенный момент времени. (как коммит в гите, к нему можно откатиться)

> Перед тем как делать снимок, нужно останавливать работу ВМ поскольку могут записаться не все файлы
> 

Разница репликации диска и снимка: диск находится в одной зоне доступности и реплицируется только в ней. Снимки же реплицируется во все зоны доступности.

> По этому, чтобы перенести ВМ в другую зону, достаточно создать в этой зоне копию ВМ из снимка загрузочного диска.
> 

### **Создание снимка**

Для того чтобы создать снимок необходимо обеспечить целостность данных, для этого:

1. Подключиться к ВМ через SSH (ssh имя@ip)
2. Ввести : `sync` (ничего не произойдет)
3. Ввести: `df -h` (это выдаст файлы, нужен / потому что это корневая папка в линуксе (нужная точка монтирования))
4. Для заморозки файловой системы:
`fsfreeze -f <точка монтирования>`

> Чтобы проверить заморожена ли файловая система достаточно ввести sudo fsfreeze --freeze <точка монтирования> и если она заморожена то выдаст ответ что ресурс занят
> 

**Намеренное повреждение системы**

Точно так же в подключенном интерфейсе к ВМ через ssh выполяем последовательно команды:

1. `apt-get update`
2. `apt-get dist-upgrade`
3. Имитация повреждения системы: `sudo rm -rf --no-preserve-root /` попросят подтвердить удаление всех данных.

### **Что такое образы и публичные образы**

> Допустим, я разработал первую версию веб-сервиса и готовлюсь открыть ее для пользователей. В ВМ уже отлажено рабочее окружение для приложения, выверены настройки служб. Осталось ее реплицировать, чтобы сервис оставался доступен, даже при неполадках.
> 

Можно развернуть ВМ из снимка диска или из образа. Образы и снимки созданные в одной зоне доступности , доступны и в других.

В основном образы используют, чтобы быстро создать загрузочный диск ВМ. Оптимальны для распространения ПО, например дистрибутивов ОС или дисков с установленными программами. Сервис - это как раз диструбутив ОС с предустановленными и настроенными приложениями

Создание ВМ из образа происходит быстрее чем со снимка.

**Использование готового образа**

Это значит что можно создать ВМ с уже установленной ОС.

Так же можно выбрать образ с уже установленными приложениями (в Cloud Marketplace)

> например если сервис будет хранить данные в БД, то можно сразу создать ВМ с предустановленной Postgres Pro Enterprise Database, работающей поверх Debian.
> 

**Перенос локальной вычислительной машины в Computer Cloud**

Для этого нужно подготовить файл образа ВМ (поддерживаются образы форматов Qcow2`,`VMDK`или`VHD) и загрузить его в бакет Yandex Object Storage, после чего он станет доступен при создании ВМ.

**Создание публичных образов**

Чтобы другие пользователи могли создавать ВМ и диски с помощью загруженного образа, нужно открыть к нему доступ, тогда он станет публичным. Делается не из консоли, а из интерфейса командной строки Yandex Cloud CLI.

1. [Установите и настройте](https://cloud.yandex.ru/docs/cli/quickstart) Yandex Cloud CLI.
2. В командной строке выполните команду:

```
yc resource-manager folders list
```

Результат:

```
+----------------------+---------+--------+--------+
|          ID          |  NAME   | LABELS | STATUS |
+----------------------+---------+--------+--------+
| b1gdf1scqef5bpqrpo5j | default |        | ACTIVE |
+----------------------+---------+--------+--------
```

Скопируйте название каталога, где хранится образ. В примере это `default`.

1. Назначьте системной группе `allAuthenticatedUsers` роль `compute.images.user`:

```
yc resource-manager folder add-access-binding default \
  --role compute.images.user \
  --subject system:allAuthenticatedUsers
```

Готово. Вы открыли всем аутентифицированным пользователям Yandex Cloud доступ к папке с образом.

Чтобы просмотреть список публичных образов, введите команду:

```bash

yc compute image list --folder-id standard-images

```

## 4. Виртуальная сеть

### **Виртуальные сети, подсети, IP-адресация**

**Сети и подсети**

Физические серверы соединяются между собой физической сетью. Виртуальные сервера соединяются между собой поверх физической сети, виртуальной сетью.

Чтобы соединить несколько виртуальных машин, необходимо создать облачную сеть. ВМ и базы данных в одной сети видят друг друга, те что в разных - нет. Кроме облачной сети необходима еще и подсеть - подмножество сети в конкретной зоне доступности

> по умолчанию для одной зоны создается одна подсеть (но этим можно управлять)
> 

**IP-адреса**

При создании подсети можно выбрать, какие IP-адреса будут выдаваться устройствам в этой подсети. Для этого можно выбрать любой диапазон адресов из:

- 10.0.0.0/8
- 172.16.0.0/12
- 192.168.0.0/16

> эти диапазоны зафиксированы в  стандарте RFC1918 как немаршрутизируемые в интернете и используются только в локальных сетях.
> 

Стоит учесть что:

- длина префекса от /16 до /28

> Подсеть 10.0.0.0/17 создать можно, а 10.0.0.0/15 или 10.0.0.0/29 — нет.
> 
- первые два адреса подсети выделяются под:
    - шлюз (`x.x.x.1` для маски сети `/24`)
    - DNS-сервер (`x.x.x.2` для маски сети `/24`)

> использовать их под адреса ВМ или других ресурсов не получится
> 
- Внутри облачной сети диапазоны IP-адресов не могут пересекаться, но если вне облачной сети, то могут, тк они изолированы друг от друга

> Внутренние IP-адреса не меняются в течении всего времени существования облачного ресурса, при создании их можно выбрать или они будут выбраны автоматически в выбранной подсети
> 

ВМ или БД можно выдать так же публичный адрес, он будет принадлежать маршрутизируемому диапазону (например `130.193.32.0/19`), при помощи этого адреса облачные ресурсы могут обмениваться данными с интернетом или другими ресурсами из других облачных сетей.

Публичные адреса сопоставляются с внутренними  с помощью [one-to-one NAT](https://ru.wikipedia.org/wiki/NAT), те одному внешнему адресу соот один ресурсу в конкретной облачной сети.

> NAT - это механизм в сетях TCP/IP который позволяет изменять IP-адреса, то есть внутренние адреса могут взаимодействовать с внешними при помощи этого механизма.
> 

### **Создание новой сети с подсетями и ВМ**

Облачные сети (Virtual Private Cloud, VPC) являются частью публичного облака, которая соединяет ресурсы воедино

> (пользовательские, инфраструктурные, платформенные и прочие)
> 
> 
> Изначально при создании облака в нем появляются автоматически подсети, но их может не хватить
> 

**Создание единой для всех ресурсов облака изолированную сеть с ВМ и другими объектами инфраструктуры**

по алгоритму из [урока2](https://practicum.yandex.ru/trainer/ycloud/lesson/1da0fe85-3837-4eb4-8071-28199a413c83/)

Чтобы ВМ полноценно заработала, необходимо организовать доступ в интернет. Есть 3 способа:

- [Назначить](https://cloud.yandex.ru/docs/compute/operations/vm-control/vm-attach-public-ip) машине публичный IP-адрес
- [Включить NAT](https://cloud.yandex.ru/docs/vpc/operations/enable-nat) для подсети
- Установить NAT-сервер и создать соответсвующий маршрут

> для безопасности лучше выбрать 2 или 3 вариант, чтобы у сервера не было прямого доступа в интернет, в этом случае нужно устанавливать отдельный сервер (бастион-хост), который будет противостоять атакам извне.
> 

**Проверка доступа сервера:**

В командной строке ввести команду:
`ping <публичный IP-адрес сервера>`

> по умолчанию эта команда будет продолжать отправлять эхо-запросы на дисплей до тех пор, пока не будет получено прерывание (Ctrl-C) БОЛЬШЕ ТУТ
> 

### **Публичные IP-адреса**

**Внутренние IP-адреса** - ВМ доступны только внутри облачной сети

**Публичные IP-адреса** (белые или внешние) - ВМ  видна и внешнему миру.

> Он присваивается по умолчанию при создании облачного ресурса с публичным адресом (если выставлены соотв. настройки). Адрес по умолчанию динамический (с запуском ресурса обновляется)
> 

**Динамические IP-адреса** - освобождаются при остановке ресурса и сохраняются при перезагрузки.

**Статические IP-адреса** в любом случае сохранятся, а также их можно зарезервировать и использовать позже, даже если они не привязаны к ресурсу

### **Статическая маршрутизация**

можно направлять трафик из подсети на заданные диапазоны IP-адресов через ВМ, указанные в качестве [шлюза](https://is.gd/lEbrCJ) (next hop).

> Для этого используются таблицы маршрутизации, они содержат статические маршруты, состоящие из префикса целевой подсети в нотации CIDR и внутреннего IP-адреса шлюза
> 

Чтобы создать таблицу маршрутизации со статическим маршрутом:

1. Virtual Private Cloud - Таблицы маршрутизации - Создать таблицу маршрутизации.
2. Указать название таблицы - добавить статический маршрут - Нажать на кнопку создать таблицу маршрутизации

Таблица маршрутизации привязывается к подсети и не может содержать префиксов. Трафик из подсети с привязанной таблицей будет направляться к указанным в  маршрутах префиксам через соответствующий адрес шлюза.

> Префикс 0.0.0.0/0 в маршруте значит, что весь трафик уйдет через указанный этим префиксом шлюз, если он не направлен по другим шлюзам.
> 

Пример: к подсети с CIDR 10.1.0.0/24 привязана таб.марш с такими маршрутами:

| Имя | Префикс | Шлюз |
| --- | --- | --- |
| another-network | 192.168.0.0/16 | 10.1.0.5 |
| internet | 0.0.0.0/0 | 10.1.0.10 |

Трафик в подсеть 192.168.0.0/16 (которая в другой виртуальной сети (ВС)) будет направляться через ВМ с адресом 10.1.0.5 (с условием что у ВМ есть интерфейс в другой ВС). Остальной трафик уйдет черех ВМ 10.1.0.10, при этом переопределение маршрута для префикса 0.0.0.0/0 может повлиять на внешнюю доступность ВМ из подсети с таблицей, где есть такой маршрут.

> В Yandex Cloud поддерживаются префиксы назначенные только вне виртуальной среды (для другой сети или вашей локальной)
> 
> 
> При создании маршрута в качестве шлюза можно указать внутренний IP-адрес, который еще не используется (не привязан к ВМ), в этом случае он заработает, когда запустится ВМ с соотв IP-адресом
> 

**Для чего используют статические маршруты**

Две схемы ([урок4](https://practicum.yandex.ru/trainer/ycloud/lesson/eaa7c160-efbf-4c73-bf74-4ce4c24331e2/)):

1. Сетевой маршрут строится до нужного префикса через одну ВМ. В качестве шлюза используется внутренний IP-адрес NAT INSTANCE 1
2. Отказоустойчивая схема с маршрутами в нескольких зонах доступности.

> Создаются ВМ в разных зонах доступности и прокладываются через них маршруты до одной подсети назначения. Если ВМ в одной зоне выйдет из строя - у ВМ других зон сохранится связанность с подсетью назанчения.
> 

**Изменение маршрутов трафика в интернете**

Если префикс назначения у маршрута из таблицы указан префикс адресов из интернета, то доступ к таким адресам и с таких адресов станет невозможным через публичные IP-адреса ВМ из подсетей, к которым привязана эта таблица

> Допустим есть vm-1 (ВМ) с публичным IP-адресом, подключенная к подсети my-subnet. Если к подсети првязать таблицу my-route-table с маршрутом для префикса 0.0.0.0/0 (все адреса) через шлюз 10.0.0.5 то доступ через публичный адрес к vm-1 пропадет.
> 
> 
> Это произойдет потому что весь трафик в подсеть ранее шедший в my-subnet, теперь будет направляться через адрес шлюза
> 

Чтобы сохранить входящую связность с облачными ресурсами через публичный адрес можно:

- вынести ресурсы с публичным адресом в отдельную подсеть
- вместо настройки маршрута в интернет ключить для подсети [доступ в интернет через NAT](https://cloud.yandex.ru/docs/vpc/operations/enable-nat)

### **Группы безопасности**

они выполняют функцию межсетевого экрана и позволяют контролировать и фильтровать входящий и исходящий трафик ВМ в соответсвии с заданными правилами (другое название - Брендмауэр)

> В консоли управления этот инструмент находится в разделе Virtual Private Cloud. Чтобы переключиться на него, нужно нажать кнопку Группы безопасности (значок щита) в панели слева.
> 
> 
> Если кнопки нету, то для создания группы нужно перейти по ссылке [https://console.cloud.yandex.ru/link/vpc/security-groups](https://console.cloud.yandex.ru/link/vpc/security-groups). После создания первой группы безопасности, кнопка появится на боковой панели каждой облачной сети.
> 

Группа безопасности назначается сетевому интерфейсу при создании или изменении ВМ и содержит правила получения и отправки трафика

**Главный принцип** - запрещено все, что не разрешено явно

> если назначить сетевому интерфейсу ВМ группу безопасности без правил, ВМ не сможет передавать и принимать трафик и у вас не получится зайти на нее по SSH
> 

**Правила**

1. Нажать на кнопку Создать группу
2. Добавить для нее правила: определить протоколы и IP-адреса для приема и отправки трафика

Если сетевому интерфейсу ВМ назначены несколько групп безопасности, то учитываются правила из всех групп. На ВМ поступит трафик, попадающий хотя бы под одно из правил в группах

> Правила хранят состояния сессий, группы безопасности отслеживают состояние соединений и сопоставляют трафик ответа с уже открытой сессией, чтобы разрешить его прием
> 
> 
> Пример: правило позволяет ВМ создать исходящую сессию на 80-й порт какого либо IP-адреса. Значит ответы от 80-го порта на источник, откуда отправлялся запрос, будут автоматически разрешены.
> 

**Виды правил:**

Определяют диапазоны адресов и портов или другие группы безопасности:

- Для входящего трафика
откуда ВМ могут принимать трафик
- Для исходящего
куда ВМ могут отправлять трафик

> Если есть правило на для исходящего но нет для входящего, то ответный трафик все равно будет поступать. Но если разрешен только входящий, то ВМ сможет лишь отвечать на запросы, но не инициировать их.
> 

Если 2 ВМ находятся в одной группе безопасности без правил, они не смогут обмениваться трафиком. А в таком случае, можно выбрать любое решение:

- Правило self для все группы (разрешит любой трафик между ресурсами в одной группе безопасности)
- Точно указать адреса и порты ресурсов в правилах

**IP-адреса и диапазоны адресов**

В правилах можно разрешить прием и отправку трафика на IP-адреса или диапазоны адресов.

- Нужно указать конкретный IP-адрес в правилах с помощью CIDR с маской /32

Чтобы разрешить передачу трафика на любые адреса по любым протоколам, нужно указать:

- CIDR 0.0.0.0 с маской /0 и в поле выбора протокола "любой"

Группы безопасности не блокируют отправку трафика на адреса сервисов, необходимых для работы ВМ и виртуальной сети:

- Адрес сервера метаданных - 169.254.169.254
- Адрес DNS-сервера - второй по порядку IP-адрес (обычно х.х.х.2) в каждой подсети

Чтобы [сетевой балансировщик](https://cloud.yandex.ru/docs/network-load-balancer/concepts/) мог проверять состояние подключённых к нему ресурсов, необходимо разрешить передачу трафика между диапазонами адресов `198.18.235.0/24` и `198.18.248.0/24` и целевыми ресурсами.

**Параметры по умолчанию**

> Если не указано иное, группа безопасности автоматически создается в новой сети и назначается ВМ при подключении к подсетям новой сети, если у них нет ни одной группы безопасности .
> 

Группа безопасности создается с рядом правил:

- Разрешен любой исходящий трафик
- Для входящего трафика разрешен:
    - трафик от членов той же группы безопасности
    - SSH-соединения на порт 22 (по TCP) с любых адресов (0.0.0.0/0)
    - RDP-соединения на порт 3389 (по TCP) с любых адресов (0.0.0.0/0)
    - любой входящий трафик по протоколу ICMP с любых адресов (0.0.0.0/0)

### **Создание группы безопасности и открываем доступ к серверу**

Создаю первую группу безопасности и делаю доступными страницы предоставляемые веб-сервером NGINX.

1. Для первого раза нужно перейти по ссылке: [https://console.cloud.yandex.ru/link/vpc/security-groups](https://console.cloud.yandex.ru/link/vpc/security-groups)
2. Нажать кнопку "создать группу"
3. Дать имя (я дал: yc-security)
4. Указать сеть (yc)

Добавить правила:

1. Для исходящего трафика:
диапазон портов 80 (HTTP) и протокол TCP, назначение "CIDR" 0.0.0.0/0
По аналогии для портов 443 (HTTPS) и 22 (SSH)
2. Для входящего трафика:
для портов 80 и 22 чтобы подключаться к веб-серверу и управлять ВМ извне

> Если инициировано соединение по определенному порту и протоколу с ВМ и есть исходящее правило, то значит и на входящий трафик будет разрешена передача данных в эту же сеть, на этот же протокол и порт.
> 
> 
> Если назначить сетевому интерфейсу ВМ группу безопасности без правил, ВМ не сможет передавать и принимать трафик.
> 

Для проверки нужна ВМ подключенная к сети, к которой были созданы правила (у меня это "yc", я при создании ВМ выбрал ее подсеть)

После подключения по SSH установим веб-сервер NGIN (по умолчанию он отсутствует): `sudo apt-get install nginx`
Установка возможна поскольку по правилам открыть 80 порт: команда apt-get использует его для получения пакетов с ПО.

После установки сервер автоматически запустится и будет доступен извне благодаря открытому порту 80. Чтобы проверить нужно зайти через браузер на публичный IP-адрес ВМ.

> но ничего не сработает если не обновить ВМ как в уроке 3
> 

## 5. Балансировка нагрузки

### **Балансировка нагрузки**

> Пример: неожиданный наплыв посетителей на сайт, чтобы его пережить потребуется развертывание копий сайта на нескольких ВМ, в таком случае нагрузка равномерно распределится между ними.
> 

Если машин 5 под один веб-сервис, то каждой ВМ достанется 20% запросов. Такой подход называется **сетевой балансировкой**

Как работает:

Перед сайтом и ВМ ставят **балансировщик** - приложение которое принимает запросов от пользователей и распределяет их по ВМ, а затем получает от ВМ ответы и передает (проксирует) их пользователям

> При этом сервису, передающему трафик, не нужно знать адреса и названия ВМ: процедура называется абстрактностью имен
> 

Балансировка также защищает веб-приложение от выхода ВМ из строя.

> Если ВМ не сможет обрабатывать запросы из-за неполадок, балансировщик перераспределит нагрузку между другими серверами
> 

Можно незаметно для пользователей обновлять код сайта или веб-приложения на серверах.

> Просто поочередно убирать ВМ из-под балансировки, обновить софт, после чего вернуть под балансировку
> 

Для максимальной доступности сервиса, нужно размещать ВМ в разных зонах доступности.

### **Yndex Network Load Balancer**

Для настройки необходимо знать 2 базовых понятия:

1. **Целевая группа**
т.е. набор серверов или других облачных ресурсов, по которым распределяются запросы пользователей.
    
    Целевая группа выглядит как список внутренних IP-адресов и подсетей, к которым эти адреса относятся.
    
    Если нужно распределить трафик по 5 ВМ, в этом случае целевая группа балансировщика может выглядеть так:
    
    `10.10.10.15, e9b7a3k9rqq3j0j36m9u10.10.10.20, e9b7a3k9rqq3j0j36m9u10.10.20.31, e2lgvksek5io187a48q510.10.20.10, e2lgvksek5io187a48q510.10.30.20, b0cnsvg8jfoe938ktqp4`
    
    Перечислены все 5 внутренних IP и для каждого указан идентификатор подсети.
    
2. **Обработчик**
Приложение принимает соединения от пользователей, распределяет их между IP-адресами Целевой Группы, а затем передает обратный трафик клиентам.

Адресация трафика строится по принципу 5-tuple:

- учитывает адрес и порт отправителя,
- адрес и порт целевого (принимающего) облачного ресурса,
- протокол передачи информации

> для приема трафика обработчик использует порты от 1 до 32767
> 

При создании сетевого балансировщика необязательно сразу настраивать обработчик, если хочется добавить его позднее

Кроме того, можно задать несколько обработчиков. Это пригодится, если запущенный на ВМ сервис предпологает использование нескольких портов **одновременно**.

> К примеру, используется надстройка над Git  наподобие GitLab. Значит, одновременно должны быть доступны и веб-интерфесы, и сервер Git, работающие на разных портах.
> 

Целевую группу можно подключить к нескольким балансировщикам - например, чтобы балансировщики на портах 80 и 443 смогли обрабатывать и HTTP- и HTTPS- запросы. Однако в этом случае придется использовать разные целевые (принимающие) порты. Если группа подключена к одному балансировщику на порту 8080, то к другому балансировщику придется ее подключить на порту 8081.

После подключения целевой группы балансировщик начнет проверять состояние целевых ресурсов и сможет распределять нагрузку между ними

### **Проверка состояния**

Создан сетевой балансировщик, настроен обработчик и указана целевая группа из 5 ВМ, на каждой из которых работает копия сайта.

> Одна ВМ вышла из строя и чтобы балансировщик узнал о неполадке и перестал проксировать тарфик на проблемную ВМ, необходимо настроить проверку состояния.
> 

**Проверка состояния** - специальный запрос от балансировщика по протоколу TCP или HTTP

Например, балансировщик раз в 10 секунд запрашивает у каждой ВМ страницу по HTTP. Если все ВМ за отведенное время отдают код `200,` их состояние - `Healthy` (от англ - здорова). Значит, ВМ готова принимать тарфик, в противном случае - Unhealthy (нездорова). Балансировщик обрабатывает результат проверки и затем перестает отправлять трафик на ВМ

Когда ВМ воссстанавливается и успевает за отведенное время отдать код 200 - ее статус меняется на Healthy

Подробнеее о статусах ресурсов в [документации](https://cloud.yandex.ru/docs/network-load-balancer/concepts/health-check)

### **Знакомство с Yandex Cloud CLI**

Создавать ВМ из веб-интерфейса не круто и не по программистски. По этому будем автоматизировать создание ВМ - интерфейсом командной строки (**CLI, Command Line Interface**)

1. Установка на свой ПК утилиту `yc` , которая представляет собой интерфейс командной строки Yandex Cloud CLI, и настройте её (создайте профиль) по [инструкции в документации](https://cloud.yandex.ru/docs/cli/quickstart).
    
    > Чтобы автоматически добавился путь до CLI в переменную PATH необходимо установить zsh (Z shell):
    > 
    > 1. Видео в котором его устанавливают: [https://www.youtube.com/watch?v=XKsZph6XFqQ](https://www.youtube.com/watch?v=XKsZph6XFqQ)
    
    > Дальше все по документации (мой первый полученный OAuth-токен в сервисе Яндекс.OAuth. : y0_AgAAAABILCSCAATuwQAAAADeFOMS7UKvjVnQThOntRdGs_Ez3WIdBfQ)
    > 
    > 
    > Чтобы открыть zsh в консоли, нужно набрать: zsh
    > и все...
    > 
2. Создать файл `startup.sh` со следующим содержимым:
`#!/bin/bash`
    
    `apt-get updateapt-get install -y nginxservice nginx startsed -i -- "s/nginx/Yandex Cloud - ${HOSTNAME}/" /var/www/html/index.nginx-debian.htmlEOF`
    
    > Нужно просто создать файл с указанным расширением .sh - это файл скрипта для Bash, он содержит инструкции, написанные на языке Bash и может быть выполнен путем ввода текстовых команд в интерфейсе командной строки оболочки.
    > 
    > 
    > Файл потом указывается в шаге 3, если знать где сохранить файл чтобы не прописывать путь, можно так сделать, я же просто сохранил где удобно и потом дописал путь.
    > 

**Создание ВМ с помощью Yndex Cloud CLI**,

1. Нужно запустить командную оболочку на своем ПК
2. Выполнить команду:
`yc compute instance create \
--name demo-1 \
--hostname demo-1 \
--metadata-from-file user-data=startup.sh \
--create-boot-disk image-folder-id=standard-images,image-family=ubuntu-2004-lts \
--zone ru-central1-a \
--network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4`
    
    > Большинство команд в Yndex Cloud CLI построено по одному принципу:
    > 
    > - cперва название утилиты `yc`
    > - потом указывается сервис Yndex Cloud, к которому мы обращаемся (в данном случае Compute Cloud, поэтому используем слово `compute`)
    > - потом ресурс, с которым будем работать (в данном случае это ВМ - `instance`)
    > - в конце действие, которое нужно выполнить с этим ресурсом(в данном случае создать - `create`)
    > 
    > После этого идут параметры и/или флаги
    > в примере в качестве флагов используются:
    > 
    > - `-name demo-1` — задаём виртуальной машине имя `demo-1`;
    > - `-hostname demo-1` — задаём имя хоста (тоже `demo-1`);
    > имя ВМ и хоста - разные вещи, первое для простого различия, а второе используется для присвоения ВМ внутреннего [FQDN](https://ru.wikipedia.org/wiki/FQDN) (полностью определенного имени домена) - ее полного адреса в облачной сети. Подробнее в [док-ии](https://cloud.yandex.ru/docs/compute/concepts/network#hostname)
    > - `-metadata-from-file user-data=
    > /home/smvn/Public/Yandex_DevOps/folder_script/startup.sh` — указываем, что при создании ВМ нужно взять метаданные из скрипта `startup.sh`;
    > - `-create-boot-disk image-folder-id=standard-images,image-family=ubuntu-2004-lts` — указываем, что загрузочный диск ВМ нужно создать из стандартного образа с OC Ubuntu 20.04;
    > - `-zone ru-central1-a` — определяем зону доступности, в которой будет создана ВМ;
    > - `-network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4` — указываем, в какой подсети для ВМ будет создан сетевой интерфейс с IPv4-адресом.
    > В примере ВМ создается в сети с именем `default` Но если нужно, можно создать в другой сети, например (yc), имя подсети будет другим: `yc-ru-central1-a`.
    > 
    > Чтобы команды лучше читались, их разбивают на несколько строк с помощью символа `\` . Благодаря ему, командная строка понимает, что вводится одна, а не несколько команд. В cdm (^) и PowerShell (`)
    > 
    > Подробнее о Yandex Cloud CLI, ключая справочник команд в [док-ии](https://cloud.yandex.ru/docs/cli/)
    > 
3. Проверить создались ли ВМ можно через веб-интерфейс или по крутому:
`yc compute instance list`

### **Создание балансировщика**

Инструкция в [уроке 5](https://practicum.yandex.ru/trainer/ycloud/lesson/35729789-cb10-4f73-b593-ad9b9ebc6c0c/) (для веб версии)

### **Как правильно использовать балансировщики**

Чтобы построить эффективную инфраструктуру с высокой отказоустойчивастью:

- Создать ресурсы в разных зонах доступности
    
    > Разместить копии ВМ в нескольких зонах доступности по одинаковому количеству (например 3а, 3b, 3с )
    > 
- Создавать облачные ресурсы с запасом
    
    > Если одна ВМ в зоне доступности выйдет из строя, трафик продолжит поступать в зону в том же объеме, а нагрузка на оставшиеся ВМ увеличится. Чтобы они все не вышли из строя необходимо добавить в каждой зоне доступности дополнительной вычислительной мощности (vCPU, RAM)
    > 
- Использовать разные балансировщики для разных приложений
    
    > это поможет эффективнее управлять нагрузкой
    > 
- Организовать два уровня балансировщиков
    
    > Балансировщики Yandex Cloud работают с протоколами TCP и UPD - транспортные протоколы или 4 уровня сетевой модели OSI. Называются так, потому что предназначены для обеспечения надежной передачи данных от отправителя к получателю.
    > 
    > 
    > Есть балансировщики протоколов 7 уровня - например HTTP
    > 
    > Поскольку балансировщик 7 уровня, например веб-сервер NGINX, выполняют более сложную работу с IP-пакетами (сборка, нализ, журналирование), они выиграют от предварительного распределения нагрузки на 4 уровне, оссобенно при DDoS-атаках
    > 
    > Организуйте двух уровневую архитектуру с балансировщиками на четвертом (транспортном) уровне OSI и 7 уровне приложения (например HTTP).
    > 
    > Балансировщик 4 уровня будет принимать трафик и передавать его целевой группе балансировщиков 7 уровня распределит
    > 
    > трафик по ВМ с приложениями.
    > 
    > В качестве балансировщиков 7 уровня можно использовать ВМ, на которые установили ПО для балансировки (например NGINX)
    > 

## 6. Группы вирутальных машин

### **Зачем нужны группы виртуальных машин**

Управлять большим кол-ом ВМ в ручную не просто, есть риск не отследить программный сбой или пиковую нагрузку и сервис ляжет.

Для этого и существует управление группами (или Instance Groups). Можно сгруппировать однотипные ВМ, которые могут находиться в разных зонах доступности, а затем определить, по каким правилам система работает с группами.

Все ВМ в группе автоматически создаются по шаблону.

> Вы заполните его параметры при формировании группы. Шаблон описывает конфигурацию машины: какие ей нужны системные ресурсы, как создать дополнительный диск, какие сетевые параметры применить, создавать ли пользователей в системе автоматически и т.д.
> 

Создание, обновление и удаление ВМ в группах выполняется от имени так называемого [сервисного аккаунта](https://cloud.yandex.ru/docs/iam/concepts/users/service-accounts). Это учетная запись со специфичным набором привилегий (например, административным). Группе ВМ можно присвоить только один сервисный аккаунт, созданный в том же самом каталоге.

Вы также можете использовать сервисный аккаунт для работы с другими API Yandex Cloud (например для интеграции групп ВМ с сетевым балансировщиком).

### **Создание группы виртуальных машин**

По алгоритму из 2 урока 6 темы

**Сервисный аккаунт** - необходим для возможности создавать, обновлять и удалять ВМ в группе, ему нужно назначить роль `editor`

По умолчанию все операции в группе ВМ выполняются от имени сервисного акк.

**Шаблон виртуальной машины** - создается как и сама ВМ, по нему Instance Groups будет создавать новые ВМ.

**Блок "В процессе создания и обновления разрешено"**

- **Добавлять выше целевого значения**
    
    > (на сколько ВМ можно превышать размер группы)
    > 
- **Уменьшать относительно целевого значения**
    
    > (на сколько ВМ можно уменьшать размер группы)
    > 
- **Одновременно создавать**
    
    > (сколько ВМ можно сразу создавать в группе)
    > 
- **Время запуска**
    
    > (сколько времени должно пройти, прежде чем будут пройдены все проверки состояния и ВМ начнет получать нагрузку)
    > 
- **Одновременно останавливать**
    
    > (сколько ВМ можно сразу удалять)
    > 
- **Останавливать машины по стратегии** — `Принудительная`**.**
    
    > При принудительной стратегии Instance Groups самостоятельно выбирает, какие ВМ остановить.
    > 

### **Автоматическое восстановление**

Чтобы ВМ простаивала как можно меньше, Instance Groups регулярно проверяет состояние ВМ (отзывчивость приложения). Если он обнаружит какие то неполадки, то будет действовать по выбранному сценарию: перезапускать ВМ или создавать новую

**Способ автоматического восстановления при сбое** зависит от настройки политики развертывания:

- Если разрешили превышать целевой размер группы
    
    > (поле Добавлять выше целевого значения), Instance Groups будет создавать ВМ вместо не прошедших проверку.
    > 
- Если разрешили уменьшать целевой размер группы
    
    > (поле Уменьшать относительно целевого значения), Instance Groups перезагрузит ВМ.
    > 
- Если не известно заранее, достаточно ли будет перезагрузки, то следует комбинировать вышеуказанные способы восстановления
    
    > Когда одна из ВМ не пройдет проверку, Instance Groups начнет одновременно перезапускать эту машину и создавать новую. ВМ, которая первая пройдет все проверки, начнет работать, а вторая будет удалена.
    > 
    > 
    > Старые машины не удаляются до тех пор, пока не созданы новые. А если в процессе создания новой ВМ все машины в группе станут работоспособны, то сервис отменит её создание.
    > 

Автоматическое восстановление прерываемых ВМ начнётся только тогда, когда в зоне доступности будет достаточно вычислительных ресурсов. Иногда это занимает немало времени.

### **Автоматическое масштабирование**

это когда система сама отслеживает потребность в ВМ и добавлять их, а при снижении нагрузки убирать лишние, чтобы экономить ресурсы и деньги.

Для этого нужно:

1. Создать группу ВМ
2. Указать какие метрики отслеживать, обычно это:
    
    нагрузка на CPU
    
    > при загруженном на 100% процессоре сервис попросту перестаёт отзываться на действия посетителей. Можно использовать и свои метрики (например время ответа сервиса).
    > 
3. Указать целевое значение метрики
    
    > Например загрузка CPU — в среднем не больше 50%.
    > 

Но если нагрузка на ресурсы не равномерная, например если у пользователей есть возможность выгружать данные из БД в таком случае среднее значение метрики может меняться . И если после каждого всплеска и спада, удалять и создавать ВМ - это будет дорого.

По этому кол-во ВМ регулируется параметрами:

- Период стабилизации
    
    > время в течении которого кол-во ВМ не может быть уменьшено, даже если ср. значение загрузки CPU очень сильно упало. Отсчет начинается с момента принятия сервисом последнего из решений увеличить размер группы. Суть в том, что если за это время всплеск повториться, то группе будет доступна еще хоть одна ВМ, которая перехватит часть запросов.
    > 
- Время на разогрев ВМ
    
    > период времени после запуска ВМ, в течении которого значения метрик этой ВМ, связанные с потреблением ресурсов, будут проигнорированы, а в место них ср. значение по группе. Это позволяет не учитывать рост нагрузки при запуске самой ВМ.
    > 
- Промежуток измерения нагрузки
    
    > период времени для усреднения значений измеряемых метрик. Сервис измеряет значения метрик с частотой несколько раз в минуту. Но принимать решение об изменении размера группы на основании только одного полученного значения не имеет смысла — например, нагрузка CPU может резко вырасти до 100%, а затем упасть до 10% в течение буквально пары секунд.  Соотв. для менее чувствительной регулировки нужен усредненный показатель.
    > 

> Вы также можете установить в Yandex Monitoring пользовательские метрики. Например, среднее время ответа сервиса. Укажите имя метрики и ее целевое значение. Если оно будет превышено, Instance Groups создаст дополнительные машины для распределения нагрузки.
> 

### **Автоматическое масштабирование под нагрузкой**

Алгоритм создания масштабируемой группы под нагрузкой в [5 уроке 6 темы](https://practicum.yandex.ru/trainer/ycloud/lesson/105e288d-01c5-41da-a240-82719f7523b6/)

**Параметры масштабирования:**

- Тип автомасштабирования — `зональное`.
    
    > При зональном автомасштабировании количество ВМ регулируется отдельно в каждой зоне доступности, указанной в настройках группы.
    > 
- Минимальное количество ВМ в зоне — `2`.
    
    > Сервис Instance Groups не будет удалять ВМ в зоне доступности, если их там всего две.
    > 
- Максимальный размер группы — `4`.
    
    > Instance Groups не будет создавать ВМ, если их уже четыре. В этот раз размер загрузочного диска ВМ — 50 ГБ, поэтому с учётом квот на суммарный объём SSD-дисков в одном облаке смогут запуститься четыре ВМ.
    > 
- Промежуток измерения загрузки — `60 секунд`.
    
    > (это период усреднения: время, за которое следует усреднять замеры нагрузки для каждой ВМ в группе)
    > 
- Время на разогрев ВМ — `3 минуты`.
    
    > В течение этого времени ВМ не учитывается в измерении средней нагрузки на группу. Фактически данное время мы можем определить, измерив, как быстро запускается ВМ.
    > 
- Период стабилизации — `5 минут`.
    
    > Отсчитывается с момента, когда Compute Cloud принял последнее решение о том, что количество ВМ в группе нужно увеличить.
    > 
- Начальный размер группы — `4`.
    
    > Это количество ВМ, которое следует создать вместе с группой.
    > 

**Состояния группы**

- Creating instance — ВМ создаётся и запускается.
- Awaiting warmup duration — ВМ начинает принимать сетевой трафик.
    
    > ВМ в этом состоянии на протяжении периода прогрева, значение метрик у этой ВМ заменяются на метрики уже существующих, пока не закончится прогрев
    > 
- Running actual — ВМ запущена, на неё подается сетевой трафик, пользовательские приложения работают.

### **Воссоздание виртуальных машин в группе**

Чтобы проверить работоспособность настроек группы виртуальных машин, необходимо:

1. Зайти через ssh на ВМ которые работают при постоянной нагрузке (в моем случае из 4 машин осталось 2)
2. Установить приложение для стресс-тестирования Linux-систем на каждую из двух ВМ
    
    `sudo apt-get install stress`
    
3. Запустить установленное приложение для каждой ВМ
`stress -c 2`
    
    > Аргумент -c значит что при тестировании будет нагружаться процессор, а число после - это кол-во ядер процессора, которые будут нагружаться. Чтобы эксперимент удался нужно выбрать то число ядер как в шаблоне
    > 
4. На вкладке со страницей мониторинга на графике **Average CPU utilization in ru-central1-a** следите за тем, как усреднённое значение нагрузки будет постепенно расти.
Как только усредненное значение нагрузки превысит порог, червис Instance Groups начнет прогревать две доп. ВМ и вводить их в строй. Это можно увидить на странице Группы виртуальных машин.
5. Остановить стресс тест можно командой **Ctrl + C**
    
    Как только во время теста запустятся оставшиеся 2 машины, значение нагрузки процессоров в группе упадет до 50%, поскольку первая половина ВМ была нагружена полностью, а вторая не загружена вовсе.
    
    Остановив тест на 1 машине нагрузка упадет до 25% и Instance Groups и удалит лишнюю. После остановки теста на оставшейся вскоре останется 2 машины как и было.
