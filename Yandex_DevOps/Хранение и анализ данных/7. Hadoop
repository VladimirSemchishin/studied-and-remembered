# Большие данные, Apache Hadoop и Apache Spark

Изучая вопросы хранения, обработки и анализа данных, было бы неправильно обойти такую концепцию, как **большие данные (Big Data)**. Давайте рассмотрим облачные технологии для работы с большими данными.

## Big Data

Как понять, что данные по-настоящему большие? Обычно к таким относят данные, размер которых увеличивается хотя бы на 100 ГБ в день. Данные при этом могут быть и структурированными, и нет.

> Источники больших данных в современном мире — это социальные сети, сайты и СМИ, информация, которую компании собирают для бизнеса, а также интернет вещей с миллионами датчиков. Чтобы оценить масштаб, приведём лишь несколько примеров: датчики беспилотного автомобиля генерируют примерно 6 ГБ данных за каждый километр пути, морской нефтяной платформы — до 1 ТБ за неделю, а пассажирского авиалайнера — до 20 ТБ за час полёта.

> Большие данные всё активнее используются в государственном управлении и бизнесе. Например, в компьютерных играх с помощью больших данных анализируют поведение игроков и делают выводы о предпочтениях аудитории. Это позволяет лучше понимать, как развивать игру, чтобы она оставалась популярной и приносила прибыль.

Чтобы работать с такими объёмами данных в реальном времени, необходимы специальные технологии. В их основе лежат три принципа:

1. **Распределённое хранение и обработка.** 

   > Данных много, а их обработка требует больших вычислительных ресурсов, поэтому необходимы распределённые системы из большого количества узлов. Создать такую систему и обеспечить её высокую производительность — непростая задача.

2. **Горизонтальная масштабируемость.** 

   > Данные постоянно накапливаются, а задачи их обработки варьируются от относительно простых до очень сложных. Поэтому нужна возможность легко наращивать объёмы хранилища и гибко изменять количество узлов, на которых обрабатываются данные.

3. **Отказоустойчивость.** 

   > Узлов в кластере много (сотни или даже тысячи), и вероятность того, что они будут выходить из строя, довольно высока. Следует построить распределённую систему так, чтобы сбой на одном или нескольких узлах не влиял на её работу в целом.

## Hadoop

Первой широко распространённой технологией хранения и обработки больших данных стал фреймворк Apache Hadoop. Это платформа с открытым программным кодом, разработанная под эгидой фонда Apache Software Foundation. По сути, Hadoop — это набор утилит и библиотек для работы с данными, распределёнными между несколькими кластерами, каждый из которых состоит из сотен или даже тысяч узлов.

В основе экосистемы Hadoop лежит четыре модуля.

- **Hadoop Common** — набор библиотек и утилит, которые используются в других решениях, в частности для создания инфраструктуры и управления распределёнными файлами.

- **HDFS** — распределённая файловая система (Hadoop Distributed File System), отказоустойчивая и не требующая высокопроизводительного оборудования.

  > Файл в системе делится на блоки, которые распределяются между узлами вычислительного кластера (DataNode). Данные файловой системы и информация о распределении блоков и об узлах данных, содержащих эти блоки, хранится на центральном узле имён (NameNode). HDFS надёжно хранит крупные файлы за счёт дублирования и репликации блоков.

- **YARN** (Yet Another Resource Negotiator) — система управления ресурсами, обеспечивающая безопасное планирование заданий и управление данными. 

  > Это набор программ, предоставляющих удобный интерфейс между аппаратными ресурсами кластера и приложениями, использующими эти ресурсы для вычислений и обработки данных.

- **MapReduce** — система распределённых вычислений для обработки больших данных.

  Вычисления происходят локально: обрабатывающая данные программа копируется на узлы с данными и выполняется там. 

  В MapReduce входной набор данных разбивается на независимые блоки, а задание для их обработки — на подзадачи: 

  - map 

    Подзадачи map — это применение функции к блоку данных. Эти подзадачи выполняются одновременно над разными блоками, а результаты записываются на диски с исходными данными.

  - reduce.

    Подзадачи reduce — это агрегация результатов выполнения map с разных узлов.

  > Пример задачи MapReduce — подсчёт числа вхождений каждого слова в тексте. Map определяют, какие слова и сколько раз входят в каждую строку. Reduce суммируют значения. Посмотрите в [руководстве MapReduce](https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html), как решается эта задача.

Классическая конфигурация кластера Hadoop состоит из: 

- сервера имён (NameNode), 
- узла-мастера MapReduce (JobTracker) 
- набора узлов, на каждом из которых развёрнуты сервер данных (DataNode) и так называемый воркер (TaskTracker).

Все операции в MapReduce подразумевают чтение с жёсткого диска и запись на него. Часто время, необходимое для этих операций, в разы превышает время самих вычислений. Поэтому технология MapReduce хорошо работает при распределённых вычислениях в пакетном режиме: когда данные подаются на обработку отдельными большими пакетами. 

А вот для обработки потоков данных в реальном времени она не подходит. Для таких задач разработаны фреймворки распределённой потоковой обработки данных, наиболее популярный из них — это **Apache Spark**.

Одно из основных отличий Spark от Hadoop заключается в том, что он хранит результаты промежуточных вычислений в памяти, не записывая их на диск. Это даёт большой прирост в производительности.

В основе Spark лежит движок, управляющий планированием и оптимизацией выполнения заданий, а также работой с источником данных (HDFS, объектным хранилищем или БД). Поверх ядра работают библиотеки. Вот основные из них:

- **Spark SQL** — чтобы запускать SQL-подобные команды в распределённых наборах данных;
- **MLlib** — для машинного обучения;
- **Structured Streaming** — для потоковой обработки данных в реальном времени;
- **GraphX** — для задач с графами.

Spark и Hadoop используются для разных задач и дополняют друг друга.

**Hadoop** подходит, чтобы:

- обрабатывать большие наборы данных, когда объём даже промежуточных результатов вычислений превышает доступную память;
- создавать инфраструктуру анализа данных при ограниченном бюджете (Spark требует много оперативной памяти, так что его использование более затратно);
- решать задачи, если времени на них достаточно и не требуется немедленно получить результаты;
- заниматься пакетной обработкой данных, выполнять много операций чтения с диска и записи на него (например анализ исторических и архивных данных).

**Spark** подходит, когда:

- нужно анализировать потоковые данные в реальном времени;
- скорость решения задачи принципиально важна;
- задачи включают много параллельных операций с использованием итерационных алгоритмов;
- задачи связаны с машинным обучением.

# Обзор Yandex Data Proc

Создавать кластеры Hadoop и Spark вручную — непростое и небыстрое занятие. Нужно настроить виртуальные машины (ВМ), развернуть сервисы, изменить множество конфигурационных файлов...

Сервис Yandex Data Proc автоматически создаст кластеры Hadoop или Spark, настроит сеть, установит ПО и обновит его, когда выйдет новая версия. В сервисе есть интерфейсы запуска заданий и инструменты мониторинга. Data Proc интегрируется с другими сервисами Yandex Cloud и автоматически масштабирует ресурсы.

## Компоненты Data Proc

В развёрнутый кластер, помимо самого Hadoop, будут включены следующие компоненты.

**Tez** — фреймворк для обработки больших данных, содержащий ряд улучшений технологии MapReduce.

**Spark** — фреймворк для распределённой потоковой обработки данных.

**Hive** — платформа для хранения больших данных в распределённом хранилище и для управления ими.

**ZooKeeper** — служба, координирующая работу приложений. Она хранит информацию о настройках системы, обеспечивает синхронизацию распределённого выполнения групповых задач, выявляет конфликтующие задачи и нерациональное использование ресурсов.

**HBase** — распределённая NoSQL база данных (БД), основанная на модели Google BigTable и использующая HDFS. Её основная задача — хранить очень большие таблицы (миллиарды строк и миллионы столбцов) на узлах кластера.

**Sqoop** — инструмент для передачи данных между Hadoop и реляционными БД. С его помощью можно импортировать данные из реляционных СУБД в Hadoop, преобразовать их с использованием MapReduce, а затем экспортировать обратно.

**Oozie** — инструмент для управления рабочим процессом и координации заданий MapReduce. Может объединить несколько задач в единое логическое задание.

**Flume** — распределённая служба, которая собирает, сортирует и перемещает большие объёмы данных журнала событий. Она может обрабатывать потоковые данные, позволяя создавать аналитические приложения для всей экосистемы Hadoop.

**Livy** — служба, которая через REST-интерфейс обеспечивает взаимодействие с кластером Spark, включая отправку заданий или частей кода Spark, а также синхронное или асинхронное получение результатов.

**Zeppelin** — многопользовательский инструмент для анализа и визуализации данных в браузере, а также совместной работы над данными с использованием Spark. Позволяет создавать запросы к данным в Hadoop на SQL, Scala или Python и отображать результаты в виде таблиц, графиков и диаграмм.

Сервис Yandex Data Proc интегрирован с Yandex DataSphere — облачной средой для разработки моделей машинного обучения. С её помощью можно пройти весь цикл создания моделей: от эксперимента и разработки до запуска готовой версии на вычислительных мощностях Yandex Cloud. DataSphere использует бессерверные вычисления, но если вам предстоит решать ресурсоёмкие задачи, то расчёты можно запустить и на вашем кластере Data Proc.

## Кластер Data Proc

Основная сущность сервиса Data Proc — **кластер**. Он объединяет все ресурсы, доступные Hadoop: вычислительные мощности и хранилище.

Каждый кластер состоит из **подкластеров**. Подкластеры объединяют хосты, выполняющие идентичные функции:

- подкластер с управляющими хостами (например NameNode для HDFS или ResourceManager для YARN);
- подкластер для хранения данных (например DataNode для HDFS);
- подкластеры для обработки данных (например NodeManager для YARN).

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/40/01.png)

Подкластеры каждого кластера должны находиться в одной облачной сети и одной зоне доступности.

## Хранение данных

Чтобы вы не переплачивали за хранение большого объёма данных на вычислительных узлах, в сервисе реализована связь с объектным хранилищем. В него помещается основной объём данных, а на вычислительных узлах хранятся только горячие данные, к которым нужен быстрый доступ.

![image](https://pictures.s3.yandex.net/resources/2_17_1625779930.png)

Вы можете запускать задания по SSH — без непосредственного доступа к кластеру Data Proc. Поэтому, чтобы вам было удобно, журнал выполнения заданий находится в отдельном бакете в объектном хранилище. Записи в журнал делаются от имени сервисного аккаунта, указанного при создании кластера.

Для кластера Data Proc рекомендуется использовать хотя бы два бакета в объектном хранилище. Один, где сервисный аккаунт имеет права только на чтение, — для исходных данных. Второй, с полным доступом сервисного аккаунта — для журналов и результатов операций. Два бакета помогут уменьшить риски непредвиденных изменений и удаления исходных данных.

## Сеть

Все подкластеры должны находиться в одной сети, а все хосты каждого подкластера — в определённой подсети этой сети.

У хостов кластера нет публичного IP-адреса. Чтобы подключиться к кластеру Data Proc, используйте ВМ, расположенную в той же облачной сети, что и кластер. То есть вы создадите ВМ, к которой подключитесь по SSH, а с этой машины, в свою очередь, подключитесь к кластеру.

В Yandex Cloud хосты без публичных IP-адресов не имеют доступа к ресурсам за пределами виртуальной сети. Поэтому для корректной работы кластера включите NAT в интернет для нужной подсети: зайдите в раздел Virtual Private Cloud в каталоге с кластером Data Proc, выберите подсеть и включите для неё эту опцию.

# Создание кластера Hadoop

> На этом уроке вы создадите и настроите кластер Hadoop с помощью сервиса Yandex Data Proc. Hadoop предназначается для работы с большими данными, поэтому создание кластера потребует от вас больше усилий, чем на предыдущих практических работах (но гораздо меньше, чем если бы вы делали это самостоятельно).

## Создание кластера

Для хранения зависимостей заданий нашего кластера и результатов их выполнения нужно предварительно создать бакет в объектном хранилище. О том, как это сделать, мы рассказывали на одном из предыдущих занятий.

Также создайте сервисный аккаунт для доступа к кластеру. Обратите внимание: можно использовать только аккаунт с ролью `mdb.dataproc.agent`. Для автоматического масштабирования кластера сервисному аккаунту также понадобятся роли `editor` и `dataproc.agent`.

Откройте каталог, где будете создавать кластер, и выберите сервис **Data Proc**.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/41/01.png)

В открывшемся окне нажмите кнопку **Создать кластер**.

Задайте для кластера имя и выберите версию образа — 1.4. В образ включена одна из версий Hadoop и дополнительные компоненты. Некоторые вы можете устанавливать по выбору. Кроме того, в каждую версию образа входит Conda (менеджер окружений для Python) и набор инструментов машинного обучения (scikit-learn, TensorFlow, CatBoost, LightGBM и XGBoost).

Обратите внимание на то, что некоторые из сервисов обязательны, чтобы использовать другие. На следующем уроке нам понадобится сервис HIVE. Выберите его, и рядом с MAPREDUCE и YARN вы увидите напоминания о том, что они нужны для HIVE.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/41/02.png)

Вставьте в поле **публичный ключ** публичную часть SSH-ключа. Как сгенерировать и использовать SSH-ключи, мы рассказывали в [одной из практических работ](https://practicum.yandex.ru/trainer/ycloud/lesson/467fb1f2-7eb4-421c-a33c-117e1cf86b66/) о виртуальных машинах.

Выберите созданный **сервисный аккаунт** для доступа к кластеру.

Выберите **зону доступности** для кластера. Все подкластеры будут находиться в этой зоне.

Если нужно, задайте **свойства** Hadoop и его компонентов. Доступные свойства перечислены в [документации](https://cloud.yandex.ru/docs/data-proc/concepts/settings-list).

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/41/03.png)

Выберите **бакет** в объектном хранилище, где будут храниться зависимости заданий и результаты их выполнения.

Выберите или создайте **сеть** для кластера. Включите опцию NAT в интернет для подсетей, в которых размещается кластер.

Если нужно, создайте **группу безопасности**. Правила для неё вы добавите позже в сервисе Virtual Private Cloud.

Включите опцию **UI Proxy**, чтобы получить доступ к веб-интерфейсам компонентов Data Proc. У некоторых компонентов (например Hadoop, Spark, YARN и Zeppelin) есть пользовательские веб-интерфейсы, доступные на мастер-узле кластера. С помощью этих интерфейсов вы можете:

- отслеживать ресурсы кластера и управлять ими (YARN Resource Manager, HDFS NameNode);
- просматривать статус и отлаживать задания (Spark History, JobHistory);
- проводить эксперименты, совместно работать или выполнять отдельные операции (Zeppelin).

Подробности об интерфейсах вы найдёте в [документации](https://cloud.yandex.ru/docs/data-proc/concepts/ui-proxy).

## Настройка подкластеров

В состав кластера входит один главный подкластер (**Мастер**) с управляющим хостом, а также подкластеры для хранения данных (**Data**) или вычислений (**Compute**).

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/41/04.png)

В подкластерах Data можно разворачивать компоненты для хранения данных, а в подкластерах Compute — для обработки данных. Хранилище в подкластере Compute предназначено только для временного хранения обрабатываемых файлов.

Для каждого подкластера можно задать число и класс хостов, размер и тип хранилища, а также подсеть той сети, в которой расположен кластер. Кроме того, для подкластеров Compute можно настроить автоматическое масштабирование. Это позволит выполнять задания на обработку данных быстрее без дополнительных усилий с вашей стороны.

Создадим подкластер Compute с одним хостом.

В блоке **Добавить подкластер** нажмите кнопку **Добавить**.

В поле **Роли** выберите `COMPUTENODE`. В блоке **Масштабирование** включите опцию `Автоматическое масштабирование`.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/41/05.png)

Все открывшиеся настройки знакомы вам из практических работ по созданию виртуальных машин.

Автоматическое масштабирование подкластеров обработки данных поддерживается в кластерах Yandex Data Proc версии 1.2 и выше. Чтобы оно работало, в кластере с установленным Spark или Hive должен быть также установлен сервис YARN.

> Yandex Data Proc автоматически масштабирует кластер, используя для этого системные метрики нагрузки на кластер. Когда их значение выходит из установленного диапазона, запускается масштабирование. Если значение метрики превысит порог, в подкластер добавятся хосты. Если опустится ниже порога, начнётся декомиссия (высвобождение ненужных ресурсов), а избыточные хосты удалятся.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/41/06.png)

По умолчанию для масштабирования используется внутренняя метрика YARN (`yarn.cluster.containersPending`). Она показывает, сколько единиц ресурсов нужно заданиям в очереди. Выбирайте эту опцию **Масштабирование по умолчанию**, если в кластере выполняется много относительно небольших заданий.

Другой вариант — масштабирование на основе метрики загрузки процессора (vCPU). Чтобы использовать его, отключите опцию **Масштабирование по умолчанию** и укажите целевой уровень загрузки vCPU.

Настроив подкластеры, нажмите кнопку **Создать кластер**.

Сервис запустит создание кластера. После того как статус кластера изменится на Running, вы сможете подключиться к любому активному подкластеру с помощью указанного в настройках SSH-ключа.

Завершив практическую работу, не удаляйте кластер: он понадобится вам на следующем уроке.

# Подключение к кластеру и работа с Hive

На этом уроке вы научитесь подключаться к кластеру Hadoop и работать с ним на примере выполнения запросов с помощью Hive.

## Подключение к кластеру

Подключимся к управляющему хосту главного подкластера. Поскольку хостам кластера Hadoop не назначается публичный IP-адрес, для подключения к ним нужна виртуальная машина, расположенная в той же сети Yandex Cloud.

Выберите машину, которую создавали раньше, или создайте новую. Подключитесь к ней по SSH. Вы уже делали это, когда изучали [виртуальные машины](https://practicum.yandex.ru/trainer/ycloud/lesson/467fb1f2-7eb4-421c-a33c-117e1cf86b66/).

Подключитесь с этой машины к хосту главного подкластера также с помощью SSH. Для этого на машине должна быть закрытая часть SSH-ключа, открытую часть которого вы указали при создании кластера Data Proc. Вы можете скопировать ключ на виртуальную машину или подключаться к ней с запущенным SSH-агентом.

1. Скопировать ключ можно с помощью утилиты nano. На виртуальной машине выполните команду:

   `sudo nano ~/.ssh/<имя ключа>`

   В открывшийся редактор скопируйте содержимое закрытой части SSH-ключа с вашей локальной машины.

   > Подразумевается, что необходимо удалить открытый ключ и перезаписать закрытый, **НО** без табуляции сверху и снизу!!!
   >
   > Имя ключа - имя файла на ВМ которая в одной подсети с ВМ кластера.

2. Запустите SSH-агент:

   eval `ssh-agent -s`

3. Добавьте ключ в список доступных агенту:

   `ssh-add ~/.ssh/<имя ключа>`

4. Откройте SSH-соединение с хостом Data Proc для пользователя `root`, например:

   `ssh root@<FQDN хоста>`

   > Узнайте внутренний FQDN хоста главного подкластера.  Для этого в консоли управления на странице кластера перейдите на вкладку **Хосты** и выберите хост с ролью `MASTERNODE`.

   Пошаговые инструкции по различным способам подключения к кластеру Data Proc [приведены в документации](https://cloud.yandex.ru/docs/data-proc/operations/connect).

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/42/2022-07-23_22-36-17.png)

5. Проверка выполнения команд hadoop:

   `hadoop version`

   

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/42/2022-07-23_22-37-15.png)

## Запуск заданий Apache Hive

Как мы уже говорили ранее, Hive — это платформа для хранения данных и управления ими в экосистеме Hadoop. Она используется для доступа к большим датасетам, сохранённым в распределённом хранилище.

Hive позволяет работать с данными различного формата (csv, tsv, Parquet, ORC, Avro и другими), подключаться к БД и взаимодействовать с ней с помощью SQL-подобного языка запросов. Hive используется преимущественно для работы с данными в HDFS, HBase, S3-совместимых хранилищах и реляционных СУБД.

Запрос на действия с данными в Hive называется **заданием**. Задания можно запускать на управляющем хосте с помощью командной оболочки [CLI Hive](https://cloud.yandex.ru/docs/data-proc/solutions/how-to-use-hive#run-job-hive-shell), а также с помощью [CLI Yandex Cloud](https://cloud.yandex.ru/docs/data-proc/solutions/how-to-use-hive#run-hive-job-cli).

1. Для запуска Hive CLI выполните команду `hive` на управляющем хосте.

2. Проверьте, всё ли работает: выполните, например, команду `select 1;` — корректный результат выглядит так:

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/42/2022-07-23_22-38-24.png)

3. Теперь создайте внешнюю таблицу (external table) в формате Parquet, содержащую открытые данные о списке перелётов между городами США в 2018 году. Для этого с помощью Hive CLI выполните запрос:`hive> CREATE EXTERNAL TABLE flights (Year bigint, Month bigint, FlightDate string, Flight_Number_Reporting_Airline bigint, OriginAirportID bigint, DestAirportID bigint) STORED AS PARQUET LOCATION 's3a://yc-mdb-examples/dataproc/example01/set01';`

4. Проверим список таблиц, выполнив команду `show tables`. Результат должен выглядеть так:

   ![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/42/2022-07-23_22-41-33.png)

5. Запросим число перелётов с разбивкой по месяцам:

   `hive> SELECT Month, COUNT(*) FROM flights GROUP BY Month;`

   Пример результата такого запроса:

   ![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/42/2022-07-23_22-43-18.png)

   Безусловно, на одном примере сложно показать возможности сервиса Data Proc. Если вас интересует работа с большими данными в облаке, посмотрите доклады сотрудников Yandex Cloud об управлении [кластерами Hadoop](https://youtu.be/z5u5mlY2o1g) и [заданиями в Data Proc](https://www.youtube.com/watch?v=yQXu5Lx0-b0&t=2040s) на YouTube-канале Yandex Cloud.