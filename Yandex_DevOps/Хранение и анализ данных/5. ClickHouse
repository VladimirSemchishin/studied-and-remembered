### Описание ClickHouse

В этой теме вы узнаете о сервисе управляемых баз данных ClickHouse. Эта БД предназначена для задач, связанных с аналитической обработкой данных, и не подходит там, где основная часть операций — обработка транзакций. Чтобы разобраться в том, почему это так, давайте сначала разберёмся с различными сценариями работы с данными.

Базы данных помогают решать различные задачи. То, какие при этом делаются запросы, насколько их много и как соотносятся операции чтения и записи, называют **сценарием работы с данными**. Универсальной БД, которая подходит для любого сценария, не существует.

Сценарии можно разделить на две группы:

1. **Обработка транзакций**, т. е. связанных между собой операций с данными. Классический пример — банковский перевод, при котором в БД одновременно изменяются записи о количестве денег на двух счетах.
2. **Обработка аналитических запросов** (online analytical processing, OLAP). В этом случае требуется быстро извлечь из БД сведения.

Например, если у вас есть мобильное приложение, то вас интересуют его продуктовые метрики: количество уникальных пользователей, среднее время нахождения на экране, среднее время, необходимое, чтобы выполнить последовательность действий... Вы отслеживаете, как меняются метрики, и решаете, как развивать приложение. Если метрики хранятся в большой БД, а запросы к ней выполняются медленно, то анализ метрик тоже станет весьма небыстрым.

Как правило, при OLAP-сценариях:

- данные в базе не изменяются или изменяются редко (нет команд модификации существующих данных типа `UPDATE` или `REPLACE`);
- данные добавляются в базу крупными порциями (командой `INSERT`);
- большинство запросов — это операции чтения;
- данные читаются из большого количества строк и небольшого количества столбцов;
- на выходе данные фильтруют или агрегируют, поэтому результат выполнения запроса содержит гораздо меньше исходных данных;
- нет транзакций;
- нет строгих требований к консистентности данных.

Классические реляционные БД не всегда удобно использовать для задач, в которых идут частые и сложные запросы к большому массиву данных. Для решения таких задач разработаны **столбцовые** (колоночные) БД. О них мы кратко говорили [раньше](https://praktikum.yandex.ru/trainer/ycloud/lesson/654549bf-ef5c-4466-b856-d1c08b13d710).

Строковые и столбцовые БД обрабатывают аналитические запросы по-разному. Предположим, для выполнения запроса нужны данные из трёх столбцов БД. В строковой придётся полностью прочитать несколько десятков или сотен тысяч строк со всеми столбцами, а в столбцовой — только данные из этих трёх столбцов.

Посмотрите на различие в обработке запросов в строковых и столбцовых БД:



Более того, в столбцовой БД эти данные физически хранятся вместе, что ещё больше ускоряет ответ.

**ClickHouse**

[ClickHouse](https://clickhouse.tech/docs/ru/introduction/distinctive-features/) — одна из популярных столбцовых БД с открытым исходным кодом. Яндекс создал ClickHouse, когда понадобилось быстро обрабатывать аналитические онлайн-запросы к Яндекс Метрике.

[Метрика](https://metrika.yandex.ru/) — это одна из крупнейших систем веб-аналитики. Она установлена более чем на миллионе сайтов и каждый день собирает больше 20 миллиардов событий (посещений сайтов, кликов, переходов со страницы на страницу и т. д.). Объём данных превышает 3,5 петабайта (13 триллионов записей) и постоянно увеличивается, к этим данным обращаются сотни тысяч раз в день. Чтобы такая система работала стабильно, в Яндексе создали ClickHouse — распределённую столбцовую СУБД, оптимизированную для быстрого выполнения большого числа аналитических запросов к огромному объёму данных.

ClickHouse работает на любой операционной системе Linux, FreeBSD или macOS, а также доступна в виде сервиса управляемой БД в Yandex Cloud.

ClickHouse позволяет создавать БД и таблицы, загружать в них данные из разных источников и выполнять к данным запросы. Эту СУБД можно интегрировать с Apache Kafka, а также с внешними источниками данных, включая БД MySQL и PostgreSQL.

Высокая скорость работы ClickHouse достигается за счёт:

- **Шардирования**. Вы можете разделить данные на шарды (т. е. части) и хранить их на одном или нескольких хостах-репликах. Кроме того, шардирование повышает доступность БД.
- **Автоматического распараллеливания запросов** на несколько процессорных ядер одного сервера и распределённых вычислений на шардированном кластере.
- **Возможности приближенных вычислений.** Система способна выполнять запросы на основе части данных (выборки). Можно агрегировать данные не по всем ключам, а по некоторым. Иногда это помогает получить довольно точный результат, задействовав меньше ресурсов.
- **Других архитектурных особенностей**: индекса (первичного ключа), физической сортировки данных по первичному ключу с помощью merge дерева, хранения данных в сжатом виде и т. д.

ClickHouse предназначен прежде всего для работы с аналитическими запросами. Если вам нужны транзакционная целостность и построчная выборка данных по ключу — применяйте другие БД, например MySQL или PostgreSQL.

Эту СУБД используют:

- чтобы анализировать логи (и мгновенно получать полную информацию об инцидентах в системе);
- чтобы отслеживать метрики поведения пользователей на сайтах (например, переходы на страницы, клики) или в онлайн-играх;
- как аналитический инструмент, когда данные в БД ClickHouse копируются из основной БД (например, PostgreSQL или Oracle), которая медленно обрабатывает аналитические запросы.

Если вам интересны подробности о том, как устроен ClickHouse и что у неё под капотом, посмотрите доклады разработчиков:

- [Виктор Тарнавский. ClickHouse: как сделать самую быструю распределённую аналитическую СУБД.](https://www.youtube.com/watch?v=Ho4_dQk7dAg)
- [Как работает ClickHouse. Лекция в ШАД.](https://www.youtube.com/watch?v=vbhSrZxm66E)

# Создание кластера ClickHouse и подключение к нему

## Создание кластера

В этой практической работе вы создадите кластер ClickHouse. Вы уже знаете, как создавать кластеры и выставлять их основные настройки в сервисах платформы данных. Но у БД ClickHouse есть свои особенности.

Когда вы создадите кластер из двух или более хостов, сервис дополнительно создаст ещё один кластер из трёх хостов, где развернёт Apache ZooKeeper. Это служба для распределенных систем, которая управляет конфигурацией, репликацией и распределением запросов по хостам БД. Без неё кластер ClickHouse работать не будет. К ZooKeeper у пользователей доступа нет, однако его хосты учитываются при расчёте квоты ресурсов облака и стоимости сервиса.

ZooKeeper синхронизирует шарды (т. е. хосты) ClickHouse. В отличие от классических реляционных БД, у ClickHouse нет главного узла (мастера), через который добавляются данные. В ClickHouse данные можно и записывать, и читать с любого узла.

Давайте приступим к практике. Перейдите в каталог, где нужно создать кластер БД, выберите **Managed Service for ClickHouse** и нажмите кнопку **Создать кластер**.

Для практической работы нам понадобится кластер с минимальной конфигурацией: тип хоста `burstable`, класс `b3-c1-m4` и стандартное сетевое хранилище размером 10 ГБ.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/28/011.png)

Задайте настройки: введите имена для кластера и БД, а также имя и пароль пользователя. Откройте публичный доступ к хосту.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/28/021.png)

Обратите внимание: в отличие от сервисов, которые мы уже рассматривали, здесь в разделе **Настройки СУБД** можно включить опции управления пользователями и БД с помощью SQL-запросов.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/28/03.png)

Кроме того, в сервисных настройках можно включить доступ к БД из консоли управления, сервисов DataLens, Яндекс Метрики и AppMetrica, а также возможность использовать бессерверные вычисления (подробно о них мы расскажем на курсе «Serverless»). С помощью DataLens, например, вы визуализируете результаты поисковых запросов в виде графиков, диаграмм и дашбордов, а подключение AppMetrica позволит импортировать данные из этого сервиса в кластер.

Отметьте пункт **Доступ из DataLens**: он понадобится вам на одном из следующих уроков.

Нажмите кнопку **Создать кластер**.

## Подключение к базе данных

К хостам кластера ClickHouse можно подключаться через интернет или с виртуальных машин в той же виртуальной сети. Если к хостам БД открыт публичный доступ, то для подключения к ним используется шифрованное соединение.

Подключайтесь к кластеру с помощью HTTP-протокола или более низкоуровневого Native TCP-протокола. В большинстве случаев рекомендуется взаимодействовать с ClickHouse не напрямую, а с помощью инструмента или библиотеки. Официально поддерживаются [консольный клиент](https://clickhouse.tech/docs/ru/interfaces/cli/), драйверы JDBC и ODBC, клиентская библиотека для C++. Также можно использовать библиотеки сторонних разработчиков для Python, PHP, Go, Ruby и т. д.

Примеры строк подключения приводятся в [документации](https://cloud.yandex.ru/docs/managed-clickhouse/operations/connect#connection-string) и консоли управления на вкладке **Обзор** страницы кластера.

> В этой документации все сказано, но повторю:
>
> Ебучая ошибка может быть из-за расположения сертификата (в закрытой папке), нужно перенести.
>
> По шагам: 
>
> 1. Получить SSL - сертификат
>
>    `sudo mkdir --parents /usr/local/share/ca-certificates/Yandex/ && \
>    sudo wget "https://storage.yandexcloud.net/cloud-certs/CA.pem" \
>        --output-document /usr/local/share/ca-certificates/Yandex/YandexCA.crt && \
>    sudo chmod 655 /usr/local/share/ca-certificates/Yandex/YandexCA.crt`
>
> 2. Перенести сертификат в локальную папку (Изначально, сертификат будет сохранен в файле `/usr/local/share/ca-certificates/Yandex/YandexCA.crt`.)
>
> 3. В той же документации двигаться до пункта 1.5.2:  sslrootcert:<путь к сохраненному файлу SSL-сертификата> 
>    УКАЗАТЬ НОВЫЙ ПУТЬ ИЗ ЛОКАЛЬНОГО МЕСТА, ГДЕ НЕ НУЖНЫ ПРАВА СУПЕРПОЛЬЗОВАТЕЛЯ

С БД удобно работать в приложении с графическим интерфейсом. Один из вариантов — универсальный клиент [DBeaver](https://dbeaver.io/). Другие варианты вы найдёте в [полном списке клиентов](https://clickhouse.tech/docs/ru/interfaces/third-party/gui/).

Подробная информация о настройке подключения [приведена в документации](https://cloud.yandex.ru/docs/managed-clickhouse/operations/connect#connection-ide). Чтобы создать подключение к ClickHouse в DBeaver, помимо обычных параметров (адреса хоста, порта, имени БД, логина и пароля) задайте на вкладке **Свойства драйвера** настройки свойств драйвера JDBC. Укажите следующие параметры: `ssl = true`; `sslmode = strict`; `sslrootcert = <путь к SSL-сертификату>`. Как получить SSL-сертификат, вы уже узнали [на предыдущих уроках](https://praktikum.yandex.ru/trainer/ycloud/lesson/9534f8eb-8585-4b3b-8393-b68d51c06898).

При подключении DBeaver покажет номер версии ClickHouse и пинг до хоста.

![image](https://pictures.s3.yandex.net/resources/3_9_1625778758.png)

В двух следующих практических работах мы используем кластер для аналитической работы с датасетами и для создания БД ClickHouse.

> **Проверьте себя**
>
> Вы планируете поместить БД ClickHouse в облаке на четырех шардах и создаёте кластер с четырьмя хостами. Сколько хостов будет при этом создано? В поле ответа напишите число.
>
> 
>
> Ваш ответ правильный
>
> 7

# Работа с данными из объектного хранилища

В интернете выложено множество **датасетов** — структурированных наборов данных, связанных общей темой. Например в [репозитории](https://github.com/owid/owid-datasets/tree/master/datasets) проекта Our World in Data находится около тысячи разнообразных датасетов: от численности населения государств до сведений об употреблении алкоголя в США с 1850 года.

Датасеты часто выкладывают в виде CSV- или TSV-файлов. В них значения разделены запятой (comma separated values, CSV) или табуляцией (tab separated values, TSV).

Сохраняйте датасеты в объектное хранилище и анализируйте данные с помощью ClickHouse. При этом не требуется создавать БД и копировать в неё данные из датасета. Отправляйте запросы к ClickHouse — а ClickHouse сходит за данными напрямую в объектное хранилище.

В качестве примера возьмем датасет с историей метеонаблюдений за 10 лет и попробуем развеять мифы о разнице погоды в Москве и Санкт-Петербурге. Датасет содержит примерно 50 тысяч записей, он выложен в объектном хранилище Yandex Cloud и доступен всем.

Воспользуемся кластером БД, который мы создали на предыдущем уроке. Откройте его в консоли управления. Запросы к датасету будем делать через SQL-консоль. На панели слева выберите вкладку **SQL** и введите пароль пользователя. В правом поле открывшейся консоли мы и станем вводить SQL-запросы.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/29/01.png)

Как вы думаете, где зарегистрирована самая низкая температура? Наверняка в Санкт-Петербурге! Давайте проверим.

`SELECT
    City,
    LocalDate,
    TempC
FROM s3(
        'https://storage.yandexcloud.net/arhipov/weather_data.tsv',
        'TSV',
        'LocalDateTime DateTime, LocalDate Date, Month Int8, Day Int8, TempC Float32,Pressure Float32, RelHumidity Int32, WindSpeed10MinAvg Int32, VisibilityKm Float32, City String')
ORDER BY TempC ASC
LIMIT 1`

Всё-таки наши интуитивные представления не всегда верны и могут опровергаться данными.

А что насчет самой высокой температуры, скорости ветра и влажности? Проверьте сами, изменив поля в запросе (средняя скорость ветра за 10 минут — `WindSpeed10MinAvg`, относительная влажность — `RelHumidity`; сортировка по возрастанию — `ASC`, по убыванию — `DESC`). Увеличив количество выводимых данных, вы получите более точное представление (измените параметр `LIMIT` c 1 до 10).

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/29/02.png)

Но это были крайние значения. Давайте проверим, насколько в этих городах отличается климат в целом. Узнаем, например, разницу среднегодовых температур.

`SELECT
    Year,
    msk.t - spb.t
FROM
(
    SELECT
        toYear(LocalDate) AS Year,
        avg(TempC) AS t
    FROM s3(
        'https://storage.yandexcloud.net/arhipov/weather_data.tsv',
        'TSV',
        'LocalDateTime DateTime, LocalDate Date, Month Int8, Day Int8, TempC Float32,Pressure Float32, RelHumidity Int32, WindSpeed10MinAvg Int32, VisibilityKm Float32, City String')
    WHERE City = 'Moscow'
    GROUP BY Year
    ORDER BY Year ASC
) AS msk
INNER JOIN
(
    SELECT
        toYear(LocalDate) AS Year,
        avg(TempC) AS t
    FROM s3(
        'https://storage.yandexcloud.net/arhipov/weather_data.tsv',
        'TSV',
        'LocalDateTime DateTime, LocalDate Date, Month Int8, Day Int8, TempC Float32,Pressure Float32, RelHumidity Int32, WindSpeed10MinAvg Int32, VisibilityKm Float32, City String')
    WHERE City = 'Saint-Petersburg'
    GROUP BY Year
    ORDER BY Year ASC
) AS spb ON msk.Year = spb.Year`

Измените поля в запросе, чтобы проверить разницу относительной влажности.

Давайте теперь рассчитаем, где раньше начинается лето. Будем считать началом лета день, начиная с которого температура поднималась выше +15 °С хотя бы пять раз в течение 10-дневного периода (864 тысячи секунд).

`SELECT
    City,
    toYear(LocalDate) AS year,
    MIN(LocalDate)
FROM
(
    SELECT
        City,
        LocalDate,
        windowFunnel(864000)(LocalDateTime, TempC >= 15, TempC >= 15, TempC >= 15, TempC >= 15, TempC >= 15) AS warmdays
    FROM s3(
        'https://storage.yandexcloud.net/arhipov/weather_data.tsv',
        'TSV',
        'LocalDateTime DateTime, LocalDate Date, Month Int8, Day Int8, TempC Float32,Pressure Float32, RelHumidity Int32, WindSpeed10MinAvg Int32, VisibilityKm Float32, City String')
    GROUP BY
        City,
        LocalDate
)
WHERE warmdays = 5
GROUP BY
    year,
    City
ORDER BY
    year ASC,
    City ASC`

# Добавление данных

Предположим, вы работаете в метеорологической службе и постоянно изучаете датасеты с погодными данными. Сбор данных о погоде автоматизирован: на территории области расположены несколько десятков пунктов наблюдения с датчиками. Информация о температуре, давлении, влажности и скорости ветра раз в полчаса передаётся с датчиков на центральный сервер. Приложение на сервере обрабатывает данные, переводит их в нужный формат и записывает в файл. Каждый файл содержит данные за три часа наблюдений. Для прогноза нужно учитывать всю историю наблюдений за последние несколько лет, то есть все файлы потребуется собрать в одну БД.

Давайте потренируемся добавлять данные из файлов в БД ClickHouse.

На предыдущих уроках мы создали кластер, на котором развёрнута БД, и научились подключаться к нему. Продолжим работать с этой БД, а в качестве добавляемого файла возьмем уже известный вам датасет с данными о погоде в Москве и Санкт-Петербурге.

Сохраните [файл](https://storage.yandexcloud.net/arhipov/weather_data.tsv) на компьютере.

Прежде чем добавлять файл в БД, создадим в ней таблицу, куда будут вставляться данные. Перейдите в SQL-консоль кластера и выполните команду:

`CREATE TABLE <имя вашей БД>.Weather
(  LocalDateTime DateTime,
   LocalDate Date,
   Month Int8,
   Day Int8,
   TempC Float32,
   Pressure Float32,
   RelHumidity Int32,
   WindSpeed10MinAvg Int32,
   VisibilityKm Float32,
   City String
) ENGINE=MergeTree
ORDER BY LocalDateTime;`

В результате будет создана пустая таблица с полями и типами данных, соответствующими полям и типам данных в нашем файле (датасете).

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/30/01.png)

Вставим данные в таблицу с помощью клиента командной строки `clickhouse-client`. Команды для его установки (для Ubuntu):

`sudo apt update && sudo apt install --yes apt-transport-https ca-certificates dirmngr && \
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E0C56BD4 && \
echo "deb https://repo.clickhouse.com/deb/stable/ main/" | sudo tee \
/etc/apt/sources.list.d/clickhouse.list`

`sudo apt update && sudo apt install --yes clickhouse-client`

`mkdir --parents ~/.clickhouse-client && \
wget "https://storage.yandexcloud.net/mdb/clickhouse-client.conf.example" \
--output-document ~/.clickhouse-client/config.xml`

Подробности о том, как [установить клиент](https://clickhouse.tech/docs/ru/getting-started/install/) и [работать с ним](https://clickhouse.tech/docs/ru/interfaces/cli/), вы найдёте в документации ClickHouse.

Подключитесь к кластеру. Пример строки подключения посмотрите в консоли управления.

Добавим файл с данными в БД с помощью команды:

`cat weather_data.tsv | clickhouse-client \
--host <адрес вашей БД> \
--secure \
--user user1 \
--database db1 \
--port 9440 \
-q "INSERT INTO db1.Weather FORMAT TabSeparated" \
--ask-password`

> НО:
>
> 1. cat ... - после него должен быть правильный адрес имеющейся БД (той которую хотим перенести)
> 2. | clickhouse-client - это типо запуск клиента который сможет перенести данные в нужную БД
> 3. --host <адрес вашей БД>  - это имя, блин, хоста кластера. (rc1a-11c9jn87e7hmsiee.mdb.yandexcloud.net)
> 4. Пароль - тот который устанавливался при настройке клиента

Переключившись в SQL-консоль, вы увидите, что данные появились в таблице.

![image](https://code.s3.yandex.net/Cloud/CloudEngineer/DB/30/02.png)

Данные в БД можно загружать и другими способами: из приложений или клиентов с графическим интерфейсом (например DBeaver). В этом случае подключение к БД и передача данных будут идти по HTTP-протоколу через порт `8443`.

Теперь вы можете анализировать 10-летний срез данных о погоде в Москве и Санкт-Петербурге непосредственно в ClickHouse, без обращений к внешним источникам. Попробуйте, например, выяснить, какой день был самым ветреным в этих городах.

После практической работы остановите кластер, но не удаляйте его. Кластер ещё понадобится, когда мы будем рассматривать сервис визуализации и анализа данных Yandex DataLens.

# Особенности сервиса управляемых баз данных ClickHouse

На этом уроке мы рассмотрим особенности реализации СУБД ClickHouse в Yandex Cloud.

## Типы хранилища

При создании кластера ClickHouse вы можете выбрать 

- стандартное сетевое (network-hdd) хранилище 

- быстрое сетевое (network-ssd), 

- стандартное сетевое (network-hdd) хранилище 

  > Сетевые хранилища используют обычные сетевые диски: такие же, как в виртуальных машинах. 
  >
  > Стандартное сетевое хранилище заметно дешевле других вариантов. Но если скорость доступа к БД вас не устраивает, то выбирайте быстрое сетевое или быстрое локальное хранилище.

- хранилище на нереплицируемых SSD-дисках (network-ssd-nonreplicated). 

  > Нереплицируемые диски — это, по сути, быстрые сетевые хранилища на SSD-дисках, для которых не предусмотрена репликация на уровне облака. Производительность системы повышается за счет снижения надёжности хранения данных. Но для управляемых БД этот недостаток не критический: репликацию можно настроить на уровне сервиса.

- быстрое локальное (local-ssd), 

  > Особенность локального хранилища заключается в том, что если локальный диск откажет, все сохранённые на нём данные будут потеряны. Поэтому, при выборе такого хранилища сервис автоматически создаст отказоустойчивый кластер минимум из двух хостов.

Также вы можете использовать **Гибридное хранилище**. Часто используемые, горячие данные хранятся на дисках сетевого хранилища, а редко используемые, холодные — в объектном хранилище Yandex Cloud.

## Обновления СУБД

Релизы ClickHouse выходят довольно часто. Поэтому сервис управляемых БД ClickHouse использует небольшой набор версий СУБД и регулярно его актуализирует. Кластеры с устаревшей, т. е. уже не поддерживаемой версией ClickHouse автоматически обновляются.

Сервис использует два типа версий: с расширенным периодом поддержки (LTS — long term support) и промежуточные.

LTS-версии выходят раз в полгода. Поддерживаются только две таких версии: текущая и предыдущая. То есть поддержка LTS-версии длится один год. Неподдерживаемая LTS-версия обновляется сразу до текущей.

![image](https://pictures.s3.yandex.net/resources/1_39_1626202524.png)

При выходе новой промежуточной версии прекращается поддержка самой старой из них. При этом одновременно поддерживается не более трёх промежуточных версий.

![image](https://pictures.s3.yandex.net/resources/2_26_1626202526.png)

## Резервное копирование

Сервис каждый день автоматически выполняет резервное копирование БД, а также позволяет создавать резервные копии вручную. Они записываются в хранилище данных. Стоимость хранения копий смотрите в [правилах тарификации](https://cloud.yandex.ru/docs/managed-clickhouse/pricing#rules-storage). Сейчас хранение не тарифицируется, пока суммарный размер БД и всех резервных копий не превышает выбранного размера хранилища. Любые копии (и автоматически, и вручную созданные) гарантированно хранятся семь дней.

Любые резервные копии делаются по инкрементальной схеме: если хотя бы в одной копии есть идентичные фрагменты данных и эти фрагменты не старше 30 дней, то они не дублируются.

![image](https://pictures.s3.yandex.net/resources/3_19_1626202529.png)

Данные в резервной копии хранятся только для таблиц, использующих движки семейства [MergeTree](https://clickhouse.com/docs/ru/engines/table-engines/mergetree-family/mergetree/). Это наиболее функциональные движки таблиц ClickHouse. Когда в таблицу на таком движке вставляется большое количество данных, эти данные записываются частями, которые затем объединяются по определённым правилам в фоновом режиме. Для остальных движков в резервной копии хранятся лишь схемы таблиц.

## Шардирование

[Шардирование](https://practicum.yandex.ru/trainer/ycloud/lesson/177daad8-08a3-4543-a985-d076124316a5/) используется для горизонтального масштабирования кластера, при котором части одной БД ClickHouse размещаются на разных шардах. 

**Шард** — это один или несколько хостов-реплик. Запрос на запись или чтение в шард можно отправить на любую его реплику, выделенного мастера нет.

Чтобы распределить данные по шардам, нужно создать распределённую таблицу. Части данных фактически хранятся в нижележащих таблицах на хостах каждого шарда, а распределённая таблица маршрутизирует запросы к этим таблицам.

ClickHouse определяет, на какой шард поместить новые данные, с помощью ключа шардирования. Выбирайте ключ так, чтобы данные логично распределялись по шардам и данные разных шардов не были связаны между собой.

Кластеры управляемых БД ClickHouse изначально создаются с одним шардом. Чтобы воспользоваться преимуществами шардирования, вам понадобится добавить еще один или несколько шардов и создать распределённую таблицу.

## Словари

**Словарь** — это хранилище данных типа «ключ-значение», которое полностью или частично находится в оперативной памяти сервера ClickHouse.

Основное преимущество словарей — высокая скорость работы по сравнению с операциями JOIN. Словари полезны, когда приходится часто обращаться к справочнику, чтобы получить набор значений по ключу.

В качестве источников данных словарей могут выступать встроенные словари ClickHouse или внешние источники: HTTP-ресурсы или другая БД (MySQL, ClickHouse, MongoDB, PostgreSQL).

Сервис также содержит встроенный словарь-геобазу и набор функций для работы с ним. Геобаза позволяет:

- получить имя региона по его идентификатору на нужном языке;
- получить идентификатор города, области, федерального округа, страны, континента по идентификатору региона;
- проверить, что один регион входит в другой;
- получить цепочку родительских регионов.

Подробнее о функциях для работы со встроенными словарями [читайте в документации](https://clickhouse.tech/docs/ru/sql-reference/functions/ym-dict-functions/).

Если встроенная геобаза вам не подходит, подключите к ClickHouse [собственную геобазу](https://cloud.yandex.ru/docs/managed-clickhouse/operations/internal-dictionaries).

## Машинное обучение

Сервис позволяет анализировать данные с помощью моделей машинного обучения [CatBoost](https://catboost.ai/) без использования дополнительных инструментов. Чтобы применить модель, подключите её к кластеру и вызовите в SQL-запросе с помощью встроенной функции `modelEvaluate()`. В результате выполнения запроса модель выдаст предсказания для каждой строки входных данных. Пример работы с моделями машинного обучения в ClickHouse [приведен в документации](https://cloud.yandex.ru/docs/managed-clickhouse/operations/ml-models).

## Тарификация

При планировании расходов на кластер ClickHouse учитывайте то, что при создании кластера из двух и более хостов автоматически создаётся ещё три хоста ZooKeeper. Хосты ZooKeeper тарифицируются по тому же принципу, что и обычные: за время использования ядер процессора и оперативной памяти.

> **Проверьте себя:**
>
> Вы планируете создать кластер ClickHouse. Вы хотели бы минимизировать затраты и полагаете, что для вашей задачи достаточно одного хоста. Для вас важна скорость выполнения запросов, а отказоустойчивость — не очень (при этом вы, естественно, не хотите потерять данные). Какой тип хранилища стоит выбрать при создании кластера?
>
> - стандартное локальное
> - стандартное сетевое
> - быстрое локальное
> - быстрое сетевое



