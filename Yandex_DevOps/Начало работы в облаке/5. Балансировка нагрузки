### Балансировка нагрузки

> Пример: неожиданный наплыв посетителей на сайт, чтобы его пережить потребуется развертывание копий сайта на нескольких ВМ, в таком случае нагрузка равномерно распределится между ними.

Если машин 5 под один веб-сервис, то каждой ВМ достанется 20% запросов. Такой подход называется **сетевой балансировкой**

Как работает:

Перед сайтом и ВМ ставят **балансировщик** - приложение которое принимает запросов от пользователей и распределяет их по ВМ, а затем получает от ВМ ответы и передает (проксирует) их пользователям

> При этом сервису, передающему трафик, не нужно знать адреса и названия ВМ: процедура называется **абстрактностью имен**

Балансировка также защищает веб-приложение от выхода ВМ из строя. 

> Если ВМ не сможет обрабатывать запросы из-за неполадок, балансировщик перераспределит нагрузку между другими серверами

Можно незаметно для пользователей обновлять код сайта или веб-приложения на серверах.

> Просто поочередно убирать ВМ из-под балансировки, обновить софт, после чего вернуть под балансировку  

Для максимальной доступности сервиса, нужно размещать ВМ в разных зонах доступности.

### Yndex Network Load Balancer

Для настройки необходимо знать 2 базовых понятия:

1. **Целевая группа**
   т.е. набор серверов или других облачных ресурсов, по которым распределяются запросы пользователей.

   Целевая группа выглядит как список внутренних IP-адресов и подсетей, к которым эти адреса относятся.

   Если нужно распределить трафик по 5 ВМ, в этом случае целевая группа балансировщика может выглядеть так:

   `10.10.10.15, e9b7a3k9rqq3j0j36m9u`
   `10.10.10.20, e9b7a3k9rqq3j0j36m9u`
   `10.10.20.31, e2lgvksek5io187a48q5`
   `10.10.20.10, e2lgvksek5io187a48q5`
   `10.10.30.20, b0cnsvg8jfoe938ktqp4`

   Перечислены все 5 внутренних IP и для каждого указан идентификатор подсети. 

2. **Обработчик**
   Приложение принимает соединения от пользователей, распределяет их между IP-адресами Целевой Группы, а затем передает обратный трафик клиентам. 

Адресация трафика строится по принципу 5-tuple: 

- учитывает адрес и порт отправителя, 
- адрес и порт целевого (принимающего) облачного ресурса, 
- протокол передачи информации

> ​	для приема трафика обработчик использует порты от 1 до 32767 

При создании сетевого балансировщика необязательно сразу настраивать обработчик, если хочется добавить его позднее

Кроме того, можно задать несколько обработчиков. Это пригодится, если запущенный на ВМ сервис предпологает использование нескольких портов **одновременно**. 

> К примеру, используется надстройка над Git  наподобие GitLab. Значит, одновременно должны быть доступны и веб-интерфесы, и сервер Git, работающие на разных портах.

Целевую группу можно подключить к нескольким балансировщикам - например, чтобы балансировщики на портах 80 и 443 смогли обрабатывать и HTTP- и HTTPS- запросы. Однако в этом случае придется использовать разные целевые (принимающие) порты. Если группа подключена к одному балансировщику на порту 8080, то к другому балансировщику придется ее подключить на порту 8081.

После подключения целевой группы балансировщик начнет проверять состояние целевых ресурсов и сможет распределять нагрузку между ними

### Проверка состояния

Создан сетевой балансировщик, настроен обработчик и указана целевая группа из 5 ВМ, на каждой из которых работает копия сайта. 

> Одна ВМ вышла из строя и чтобы балансировщик узнал о неполадке и перестал проксировать тарфик на проблемную ВМ, необходимо настроить проверку состояния.

**Проверка состояния** - специальный запрос от балансировщика по протоколу TCP или HTTP

Например, балансировщик раз в 10 секунд запрашивает у каждой ВМ страницу по HTTP. Если все ВМ за отведенное время отдают код `200,` их состояние - `Healthy` (от англ - здорова). Значит, ВМ готова принимать тарфик, в противном случае - Unhealthy (нездорова). Балансировщик обрабатывает результат проверки и затем перестает отправлять трафик на ВМ

Когда ВМ воссстанавливается и успевает за отведенное время отдать код 200 - ее статус меняется на Healthy

Подробнеее о статусах ресурсов в [документации](https://cloud.yandex.ru/docs/network-load-balancer/concepts/health-check)

### Знакомство с Yandex Cloud CLI

Создавать ВМ из веб-интерфейса не круто и не по программистски. По этому будем автоматизировать создание ВМ - интерфейсом командной строки (**CLI, Command Line Interface**)

1.  Установка на свой ПК утилиту `yc` , которая представляет собой интерфейс командной строки Yandex Cloud CLI, и настройте её (создайте профиль) по [инструкции в документации](https://cloud.yandex.ru/docs/cli/quickstart).

   > Чтобы автоматически добавился путь до CLI в переменную PATH необходимо установить zsh (Z shell):
   >
   > 1. Видео в котором его устанавливают: https://www.youtube.com/watch?v=XKsZph6XFqQ

   > Дальше все по документации (мой первый полученный OAuth-токен в сервисе Яндекс.OAuth. : y0_AgAAAABILCSCAATuwQAAAADeFOMS7UKvjVnQThOntRdGs_Ez3WIdBfQ)
   >
   > Чтобы открыть zsh в консоли, нужно набрать: zsh
   > и все...

2. Создать файл `startup.sh`  со следующим содержимым:
   `#!/bin/bash`

   `apt-get update`
   `apt-get install -y nginx`
   `service nginx start`
   `sed -i -- "s/nginx/Yandex Cloud - ${HOSTNAME}/" /var/www/html/index.nginx-debian.html`
   `EOF`

   > Нужно просто создать файл с указанным расширением .sh - это файл скрипта для Bash, он содержит инструкции, написанные на языке Bash и может быть выполнен путем ввода текстовых команд в интерфейсе командной строки оболочки.
   >
   > Файл потом указывается в шаге 3, если знать где сохранить файл чтобы не прописывать путь, можно так сделать, я же просто сохранил где удобно и потом дописал путь.

**Создание ВМ с помощью Yndex Cloud CLI**, 

1. Нужно запустить командную оболочку на своем ПК 

2. Выполнить команду:
   `yc compute instance create \
   --name demo-1 \
   --hostname demo-1 \
   --metadata-from-file user-data=startup.sh \
   --create-boot-disk image-folder-id=standard-images,image-family=ubuntu-2004-lts \
   --zone ru-central1-a \
   --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4`

   > Большинство команд в Yndex Cloud CLI построено по одному принципу:
   >
   > - cперва название утилиты `yc`
   > - потом указывается сервис Yndex Cloud, к которому мы обращаемся (в данном случае Compute Cloud, поэтому используем слово `compute`)
   > - потом ресурс, с которым будем работать (в данном случае это ВМ - `instance`)
   > - в конце действие, которое нужно выполнить с этим ресурсом(в данном случае создать - `create`)
   >
   > После этого идут параметры и/или флаги
   > в примере в качестве флагов используются:
   >
   > - `--name demo-1` — задаём виртуальной машине имя `demo-1`;
   > - `--hostname demo-1` — задаём имя хоста (тоже `demo-1`);
   >   имя ВМ и хоста - разные вещи, первое для простого различия, а второе используется для присвоения ВМ внутреннего [FQDN](https://ru.wikipedia.org/wiki/FQDN) (полностью определенного имени домена) - ее полного адреса в облачной сети. Подробнее в [док-ии](https://cloud.yandex.ru/docs/compute/concepts/network#hostname)
   > - `--metadata-from-file user-data=
   >   /home/smvn/Public/Yandex_DevOps/folder_script/startup.sh` — указываем, что при создании ВМ нужно взять метаданные из скрипта `startup.sh`;
   > - `--create-boot-disk image-folder-id=standard-images,image-family=ubuntu-2004-lts` — указываем, что загрузочный диск ВМ нужно создать из стандартного образа с OC Ubuntu 20.04;
   > - `--zone ru-central1-a` — определяем зону доступности, в которой будет создана ВМ;
   > - `--network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4` — указываем, в какой подсети для ВМ будет создан сетевой интерфейс с IPv4-адресом.
   >   В примере ВМ создается в сети с именем `default` Но если нужно, можно создать в другой сети, например (yc), имя подсети будет другим:   `yc-ru-central1-a`.   
   >
   > Чтобы команды лучше читались, их разбивают на несколько строк с помощью символа `\` . Благодаря ему, командная строка понимает, что вводится одна, а не несколько команд. В cdm (^) и PowerShell (`)
   >
   > Подробнее о Yandex Cloud CLI, ключая справочник команд в [док-ии](https://cloud.yandex.ru/docs/cli/)

3. Проверить создались ли ВМ можно через веб-интерфейс или по крутому:
   `yc compute instance list`

### Создание балансировщика

Инструкция в [уроке 5](https://practicum.yandex.ru/trainer/ycloud/lesson/35729789-cb10-4f73-b593-ad9b9ebc6c0c/) (для веб версии)

### Как правильно использовать балансировщики

Чтобы построить эффективную инфраструктуру с высокой отказоустойчивастью:

-  Создать ресурсы в разных зонах доступности

  > Разместить копии ВМ в нескольких зонах доступности по одинаковому количеству (например 3а, 3b, 3с )

- Создавать облачные ресурсы с запасом

  > Если одна ВМ в зоне доступности выйдет из строя, трафик продолжит поступать в зону в том же объеме, а нагрузка на оставшиеся ВМ увеличится. Чтобы они все не вышли из строя необходимо добавить в каждой зоне доступности дополнительной вычислительной мощности (vCPU, RAM)

- Использовать разные балансировщики для разных приложений

  > это поможет эффективнее управлять нагрузкой

- Организовать два уровня балансировщиков

  > Балансировщики Yandex Cloud работают с протоколами TCP и UPD - транспортные протоколы или 4 уровня сетевой модели OSI. Называются так, потому что предназначены для обеспечения надежной передачи данных от отправителя к получателю.
  >
  > Есть балансировщики протоколов 7 уровня - например HTTP
  >
  > Поскольку балансировщик 7 уровня, например веб-сервер NGINX, выполняют более сложную работу с IP-пакетами (сборка, нализ, журналирование), они выиграют от предварительного распределения нагрузки на 4 уровне, оссобенно при DDoS-атаках
  >
  > Организуйте двух уровневую архитектуру с балансировщиками на четвертом (транспортном) уровне OSI и 7 уровне приложения (например HTTP).
  >
  > Балансировщик 4 уровня будет принимать трафик и передавать его целевой группе балансировщиков 7 уровня распределит
  >
  >  трафик по ВМ с приложениями.
  >
  > В качестве балансировщиков 7 уровня можно использовать ВМ, на которые установили ПО для балансировки (например NGINX)



